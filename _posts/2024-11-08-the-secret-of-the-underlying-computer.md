---
layout: post
title: 컴퓨터 밑바닥의 비밀 
categories: book
tags: [book, computer]
excerpt: 책을 읽고 정리한 내용입니다.
---

[컴퓨터 밑바닥의 비밀](https://m.yes24.com/Goods/Detail/125299750) 책을 읽고 정리한 내용입니다.

## Chapter 1. 프로그래밍 언어부터 프로그램 실행까지, 이렇게 진행된다

### Section 1.1 여러분이 프로그래밍 언어를 발명한다면?

- 스위치를 조작해 불 논리(boolean logic)를 표현할 수 있고, 이를 기반으로 CPU를 만들었다.
- 천공 카드(punched card)로 컴퓨터 작업 제어
- 어셈블리어(assembly language): 가산 명령어, 점프 명령어 등 몇 가지 명령어를 기계어와 대응
- 어셈블리어는 인간이 인식할 수 있는 단어가 있지만, 기계어와 마찬가지로 여전히 저수준 언어(low-level language)
- 저수준 계층의 세부 사항 vs 고수준 계층의 추상화
  - 저수준 언어는 모든 세부 사향에 대해 신경을 써야 함
  - 인간의 추상적인 표현을 CPU가 이해할 수 있는 구체적인 구현으로 자동 변환할 수 있다면 프로그래머가 생산성을 획기적으로 높일 수 있다.
- 가득한 규칙: 고급 프로그래밍 언어의 시작
  - 세부 사항이 규칙 또는 패턴으로 가득하다는 것을 발견
    - 명령어에는 문(statement)
    - 조건에 따른 이동, if-else
    - 순환, while
    - 명령어의 세부 사항만 차이가 있는데, 이런 차이를 매개변수(parameter)
- 재귀: 단계별로 계속 중첩
- 컴퓨터가 재귀를 이해하도록 만들기: 재귀 구문에 따라 작성된 코드를 트리(tree) 구조로 표현할 수 있다.
- 컴파일러(compiler)
  - 코드는 트리 형태로 표현될 수 있다. 그렇게 되면, 리프 노드(leap node)의 표현이 매우 간단하게 바뀌어서 간단하게 기계 명령어로 번역이 가능해진다. 이렇게 번역 결과를 차례대로 부모 노드에 적용하는 방식으로 올라가다 보면 결국 전체 트리를 구체적인 기계 명령어로 번역할 수 있다.
  - 이 작업을 담당하는 프로그램의 이름이 컴파일러다.
  - 이 시점부터 프로그래머는 인간이 인식할 수 있는 언어를 사용하여 코드를 작성할 수 있고, 컴파일러는 이를 CPU가 인식할 수 있는 기계 명령어로 번역하는 역할을 담당
- 해석형 언어의 탄생
  - 다양한 CPU가 탄생하게 되는데, 다른 CPU는 자신만의 고유한 언어가 존재
  - 각양각색의 CPU마다 상응하는 시뮬레이션 프로그램을 준비하면 우리 코드를 직접 서로 다른 플랫폼에서 실행할 수 있다. CPU 시뮬레이션 프로그램을 가상 머신(virtual machine)이라 한다. 이 가상 머신에는 인터프리터(interpreter)라는 별명도 있다.
- 컴파일러는 언어 구문에 따라 코드 구문을 분석하여 구문 트리로 만들고, 이 구문 트리를 C/C++ 언어처럼 기계어로 번역하여 CPU로 직접 넘기거나 자바처럼 바이트 코드(byte code)로 변환한 후 가상 머신으로 넘겨 실행한다.
- 고급 언어는 추상적 표현이 뛰어나서 사용하기 쉽지만 저수준 계층에 대한 제어 능력이 떨어진다. 따라서 직접 저수준 계층의 세부 사항을 제어할 수 있어야 하는 운영 체제 중 일부분은 어셈블리어로 작성된다.
  
### Section 1.2 컴파일러는 어떻게 작동하는 것일까?

- 컴파일러: 고수준 언어를 저수준 언어로 번역하는 프로그램
- 소스파일(source file): 인간이 인식할 수 있는 테스트 파일 형식
- 소스코드 --> 컴파일러 --> 실행 파일
- 컴파일러가 하는 첫 번째 작업: 소스 코드를 돌아다니면서 모든 토큰을 찾아내는 것
  - 토큰(token): 각 항목에 추가로 정보를 결합한 것
    |토큰 의미|토큰 값|
    |--------|------|
    |keyword|int|
    |identifier|a|
    |assign|`=`|
  
  - 어휘 분석(lexical analysis): 소스 코드에서 토큰을 추출하는 과정 
- 컴파일러는 구문에 따라 해석(parsing)해 낸 '구조'는 트리로 표현
  - 구문 트리: 토큰을 해석한 후 생성된 트리
  - 구문 분석: 트리를 생성하는 전체 과정 
- 구문 트리가 생성되고 나면 이상이 없는지 확인해야 하는데 이 과정을 의미 분석(semantic analysis)이라고 한다.
- 의미 분석이 끝나면 컴파일러는 구문 트리를 탐색한 결과를 바탕으로 좀 더 다듬어진 형태인 중간 코드(Intermediate Representation Code, IR Code) 생성
- 중간 코드 --> 어셈블리어 코드 --> 기계 명령어 
- 컴파일 과정을 거쳐 생성된 기계 명령어가 저장된 파일을 대상 파일(object file)이라 한다.
- 모든 소스 파일에는 각각의 대상 파일이 있다. 이 대상 파일들을 하나의 실행 파일로 합쳐 주는 작업을 링크(link)라고 한다. 링크를 담당하는 프로그램을 링커(linker)라고 한다.

### Section 1.3 링커의 말할 수 없는 비밀 

- 링커는 컴파일러와 마찬가지로 일반적인 프로그램이다. 
- 링커는 컴파일러가 생성한 대상 파일(object file) 여러 개를 하나로 묶어 하나의 최종 실행 파일을 생성
- 링커가 하는 일
  - 모듈 사이에 종속성(dependency) 확인
    - 참조하고 있는 외부 심벌(external symbol)에 대한 실제 구현이 어느 모듈이든지 단 하나만 있어야 한다. 링커는 이를 찾아내 연결하는 작업을 하는데 이 과정을 심벌 해석(symbol resolution)이라 한다.
  - 실행 파일 생성    
  - 재배치(relocation): 특정한 소스 파일에서 다른 모듈에 정의되어 있는 print() 함수를 참조할 때, 컴파일러가 이 소스 파일을 컴파일하는 시점에는 함수가 어느 메모리 주소(memory address)에 위치할지 정확히 알 수 없다. 따라서 컴파일러는 이 함수를 N으로 표시해 두고 일단 넘어간다. 이후 링크 과정에서 링커가 이런 표시들을 확인하고 한데 모아 실행 파일을 생성하는 과정에서 함수의 정확한 주소를 확인하고, N을 실제 메모리 주소로 대체한다.
- 심벌 해석
  - 심벌: 전역 변수(global variable)과 함수(function)의 이름을 포함하는 모든 변수 이름
  - 지역 변수(local variable)는 모듈 내에서만 사용되어 외부 모듈에서 참조할 수 없기 때문에 링커의 관심 대상이 아니다.
  - 링커가 해야 할 일은 대상 파일에 참조하고 있는 각각의 모든 외부 심벌마다 대상 정의가 반드시 존재하는지, 단 하나만 존재하는지 확인하는 것
  - 링커가 심벌에 대한 정보를 어떻게 알 수 있는가? 컴파일러가 알려준다.
    - 컴파일러는 기계 명령어를 생성할 뿐만 아니라 이 명령어를 실행시키는 데이터도 생성하는데, 이 데이터는 대상 파일에 반드시 포함되어야 한다.
    - 대상 파일에 포함된 영역
      - 명령어 부분: 소스 파일에서 정의된 함수에서 변환된 기계 명령어가 저장되는 부분이다. 코드 영역(code section)이라고 부른다.
      - 데이터 부분: 소스 파일의 전역 변수가 저장되는 부분이다. 이 부분을 데이터 영역(data section)이라고 부른다. 참고로 로컬 변수는 프로그램이 실행된 후 스택 영역에 생성되고 사용하면 제거되기 때문에 대상 파일에 별도로 저장하지 않는다.
      - 심벌 테이블(symbol table): 외부 심벌 정보를 기록하는 표
        - 내가 정의한 심벌, 즉 다른 모듈에서 사용할 수 있는 심벌
        - 내가 사용하는 외부 심벌 
- 정적 라이브러리, 동적 라이브러리, 실행 파일
  - 정적 라이브러리(static library): 소스 파일 여러 개를 미리 개별적으로 컴파일하고 링크하여 정적 라이브러리로 생성할 수 있다. 이 때 소스 파일마다 단독으로 컴파일을 한다는 것이다. 
    - 정적 라이브러리를 가져와 사용한 코드에서 실행 파일을 생성할 때는 자신의 코드만 컴파일하며, 미리 컴파일이 완료된 정적 라이브러리는 다시 컴파일할 필요 없이 링크 과정에서 그대로 실행 파일에 복제된다. 코드가 의존하는 외부 코드를 매번 컴파일하지 않아도 되기 때문에 컴파일 속도가 빨라진다.
    - 정적 링크: 대상 파일에서 데이터 영역과 코드 영역을 결합하는 것 
    - 정적 링크 단점
      - 라이브러리를 실행 파일에 직접 복사하기 때문에 C 표준 라이브러리(C standard library)처럼 거의 모든 프로그램에 적용되는 표준 라이브러리를 사용한다면 정적 링크로 생성된 실행 파일은 모두 동일한 코드와 데이터의 복사본을 갖게 된다. 이 경우 디스크와 메모리를 엄청나게 낭비할 수 있다.
      - 정적 라이브러리의 모든 내용에 종속성이 있다고 가정하면, 정적 라이브러리 코드가 변경될 때마다 해당 정적 라이브러리에 종속된 프로그램 역시 매번 다시 컴파일해야 한다.
  - 동적 라이브러리(dynamic library): 공유 라이브러리(shared library) 또는 동적 링크 라이브러리(dynamic linked library)라고 한다.
    - 정적 라이브러리를 사용하면 정적 라이브러리의 코드 영역과 데이터 영역을 모두 한데 묶어 실행 파일에 복사(copy)한다. 반면에 동적 라이브러리를 사용하면 참조된 동적 라이브러리 이름, 심벌 테이블, 재배치 정보 등 필수 정보만 실행 파일에 포함한다. 정적 라이브러리에 비해 실행 파일의 크기를 확실히 줄일 수 있다.
    - 참조된 동적 라이브러리 필수 정보는 실행 파일 내 저장된다. 이 필수 정보는 동적 링크(dynamic linking)이 일어날 때 사용된다.
    - 동적 라이브러리에 의존하는 실행 파일에는 컴파일 단계에서 필수 정보만 저장되기 때문에 동적 링크는 실제 프로그램의 실행 시점까지 미룬다.
    - 동적 링크에는 두 가지 방식이 있다.
      - 프로그램이 메모리에 적재(loading)될 때 동적 링크가 진행
        - 적재: 실행 파일을 실행하기 위해 디스크에서 읽어 메모리의 특정 영역으로 이동시키는 과정으로 이 과정에서 적재 도구(loader)라는 전용 프로세스가 실행
        - 실행 파일을 적재하고 나면 적재 도구는 실행 파일이 동적 라이브러리에 의존하는지 여부를 확인 후 필요하다면 동적 링커(dynamic linker)라는 별도의 프로세스를 실행해 참조하는 동적 라이브러리 존재 여부와 위치, 심벌의 메머로 위치 등을 확인하여 링크 과정을 마무리한다.
      - 프로그램이 먼저 실행된 후, 프로그램의 실행 시간(runtime) 동안 코드가 직접 동적 링크를 실행할 수 있다. 실행 시간 동적 링크(runtime dynamic liking)는 실행 파일이 실행될 때까지 어떤 동적 라이브러리에 의존하는지 알 필요 없기 때문에 좀 더 동적인 링크 방식이다.
    - 장점
      - 동적 라이브러리를 사용하면 의존하는 프로그램 개수가 얼마나 되었든 상관없이 디스크에 동적 라이브러리의 복사본 하나만 저장한다. 마찬가지로 메모리에 적재되는 동적 라이브러리의 코드 역시 모든 프로세스가 하나의 코드를 공유하기 때문에 하나면 충분하다. 메모리 적재와 디스크 저장에 필요한 리소스를 대폭 절약할 수 있다.
      - 동적 라이브러리 코드가 수정된다고 할지라도 해당 동적 라이브러리만 다시 컴파일하면 된다.
      - 여러 언어를 혼합하여 개발할 때도 유용하다.
    - 단점
      - 정적 링크를 사용할 때보다 성능이 약간 떨어진다.
      - 특정 메모리 주소와 독립적으로 동작하기 때문이 위치 독립 코드(position-independent code)로 불린다. 동적 라이브러리는 메모리에 단 하나의 복사본만 존재하고 해당 코드는 여러 프로세스가 공유할 수 있기 때문에 동적 라이브러리의 코드는 임의의 메모리 절대 주소(absolute address)로 참조할 수 없다.
      - 종속된 동적 라이브러리를 제공하지 않거나 그 버전이 호환되지 않을 경우 프로그램이 실행되지 않는다. 이런 동적 라이브러리 종속성 문제로 프로그램의 설치와 배포에 어려움을 겪을 수 있다. 
    - 동적 라이브러리를 사용할 때 얻는 이점이 이런 성능 손실보다 더 큰 가치가 있다.
- 재배치: 심벌의 실행 시 주소 결정하기
  - 모든 변수나 함수에 메모리 주소가 있다. 어셈블리어로 작성된 코드를 살펴보면, 명령어에 변수 정보가 전혀 없는 대신 전부 메모리 주소를 사용한다.
  - 컴파일러가 대상 파일(object file)에 메모리 주소를 확정할 수 없는 변수를 발견할 때마다 `.relo.text`에 해당 명령어를 저장하고, `.relo.data`에 해당 명령어와 관련된 데이터를 저장한다.
  - 대상 파일에 각 유형의 영역이 모두 결합되면 모든 기계 명령어와 전역 변수가 프로그램 실행 시간에 위치할 메모리 주소를 결정할 수 있다. 이어서 링커는 각 대상 파일의 `.relo.text` 영역을 하나씩 읽어 기계 명령어를 수정해야 하는 심벌이 있으면 심벌의 메모리 주소를 수정한다.
  - 링커가 프로그램이 실행된 후의 변수나 기계 명령어의 메모리 주소를 확인할 수 있는 이유가 무엇일까? 변수나 명령어의 메모리 주소는 프로그램이 실행될 때마다 변경되기 때문에 실제로 그 시점이 되어야 알수 있다. 링커는 예언자이다. 
- 가상 메모리(virtual memory)와 프로그램 메모리 구조
  - 프로그램이 실행되면 해당 프로그램의 프로세스(process)가 메모리에 적재
  - 프로세스의 형태: 커널 --> 스택 영역(함수 실행 시 정보 저장) <-- 힙 영역(동적 메모리 할당) <-- 데이터 영역 <-- 코드 영역
  - 메모리의 상위 주소(higher address)에 스택 영역이 존재한다. 그리고 그 아래에 비어 있는 큰 공간이 존재하고, 이어서 힙 영역이 존재한다. malloc 함수가 바로 이 힙 영역에서 메모리를 할당 받는다. 마지막으로 데이터 영역과 코드 영역은 실행 파일의 내용이 메모리에 적재되는 곳이다.
  - 코드 영역이 시작되는 위치는 예외 없이 0x400000에서 시작한다.
    - 운영 체제의 가상메모리 기술때문에 가능하다.
  - 가상 메모리는 말 그대로 물리적으로 존재하지 않는 가짜 메모리이다. 가상 메모리는 각각의 프로그램이 실행중일 때, 자기 자신이 모든 메모리를 모두 독점적으로 사용하고 있는 것처럼 착각하게 만든다. 예를 들어 32비트 시스템에서는 실제로 시스템에 설치된 물리적 메모리가 얼마가 되었든 자신이 4GB 메모리를 독점하고 있다고 생각한다.
  - 모든 프로그램이 동일한 표준적인 메모리 구조를 가질 수 있는 이유다. 링커가 실행 파일을 생성하자마자 실행 시 심벌의 메모리 주소를 결정할 수 있는 것도 프로그램 실행 여부와 관계없이 프로세스 메모리 구조를 알고 있기 때문이다. 코드 영역은 언제나 메모리 주소 0x400000에서 시작하고, 스택 영역은 항상 메모리의 상위 주소에 위치한다.
  - 실행 파일을 실행하려면 물리 메모리에 적재되어야 한다. 적재되면 시스템에 `가상 메모리 - 물리 메모리` 매핑 관계가 추가된다. 이런 매핑 관게를 기록한 표를 페이지 테이블(page table)이라고 한다. 각각의 프로세스에는 자신만의 페이지 테이블이 있다.

### Section 1.4 컴퓨터 과학에서 추상화가 중요한 이유

- 추상화는 표현력을 크게 향상시키고 의사소통의 효율을 올려 줄 뿐만 아니라 세부 사항을 노출할 필요가 없으므로 보호할 수도 있다.
- 시스템 설계와 추상화
  - CPU의 하드웨어는 트랜지스터 여러 개로 구성되어 있지만, 명령어 집합(instruction set)이라는 개념으로 내부 구현 세부 사항을 보호한다. 따라서 프로그래머는 트랜지스터의 세부 사항은 전혀 고려할 필요 없이 명령어 집합에 포함된 기계 명령어를 사용하여 CPU에 작업을 지시하기만 하면 된다. 그리고 기계 명령어에 대한 추상화 계층(abstract layer)은 다시 고급 프로그래밍 언어로 이어진다. 따라서 고급 언어로 프로그래밍 하는 프로그래머는 기계 명령어의 세부 사항에 신경 쓸 필요가 없으며, 고급 언어를 이용하여 CPU를 '직접' 제어할 수 있기 때문에 프로그래밍의 질적 효율성이 크게 높아진다.
  - 입출력(input/output) 장치는 파일(file)로 추상화
  - 실행 중인 프로그램은 프로세스로 추상화
  - 물리 메모리와 파일은 가상 메모리로 추상화
  - 네트워크 프로그래밍은 소켓(socket)으로 추상화
  - 프로세스와 프로세스의 종속적인 실행 환경은 컨테이너(container)로 추상화 
- 추상화는 프로그래머를 저수준 계층에서 점점 더 멀어지게 만들고, 점점 더 저수준 계층의 세부 사항도 신경 쓸 필요가 없도록 만든다. 또 프로그래밍의 문턱도 점점 더 낮추어 컴퓨터 기초가 전혀 없는 사람도 며칠 동안 간단한 학습만으로도 괜찮은 프로그램을 작성하게 해준다. 이것이 추상화의 위력이다.

## Chapter 2. 프로그램이 실행되었지만, 뭐가 뭔지 하나도 모르겠다

### Section 2.1 운영 체제, 프로세스, 스레드의 근본 이해하기

#### 모든 것은 CPU에서 시작된다 

- CPU는 스레드, 프로세스, 운영체제 같은 개념을 전혀 알지 못한다. 단지 다음 두 가지 사항만 알고 있다.
  - 메모리에서 명령어(instruction)를 하나 가져온다(dispatch).
  - 이 명령어를 실행(execute)한 후 다시 위로 돌아간다.
- CPU는 어떤 기준으로 메모리에서 명령어를 가져올까? PC
- 프로그램 카운터(program counter, PC)라고 불리는 레지스터(register)
  - 레지스터: 용량은 매우 작지만 속도는 매우 빠른 일종의 메모리 
  - PC 레지스터에 메모리에 저장된 명령어 주소가 저장됨
- CPU가 실행하는 명령어는 어디서 오는가?
  - 소스파일 --> 컴파일러 --> 실행파일 --> 디스크 --> 메모리 --> CPU
- 우리가 작성하는 프로그램에는 반드시 시작 지점이 있어야 하는데, main 함수가 바로 그것이다. 프로그램이 시작되면 먼저 main 함수에 대응하는 첫 번째 기계 명령어를 찾고, 이어서 그 메모리 주소를 PC 레지스터에 기록한다.

#### CPU에서 운영 체제까지

- CPU가 프로그램을 실행하게 하려면 실행 파일을 수동으로 메모리에 복사한 후 main 함수에 해당하는 첫 번째 기계 명령어를 메모리에서 찾아 그 주소를 PC 레지스터에 적재하면 된다는 것을 알았다.
- 운영 체제가 없어도 우리가 직접 CPU에 프로그램을 실행하도록 할 수 있다. 하지만 매우 복잡하고 번거롭다.
  - 다음과 같은 모든 작업을 직접 해야 한다.
    - 프로그램을 적재할 수 있는 적절한 크기의 메모리 영역을 찾는다.
    - CPU 레지스터를 초기화하고 함수의 진입 포인트(entry point)를 찾아 PC 레지스터에 설정한다.
  - 다음과 같은 단점도 있다.
    - 한 번에 하나의 프로그램만 실행할 수 있다. 수동으로 관리해야 하는 시스템은 멀티태스킹(multi-tasking)을 지원할 방법이 없다. 
    - 모든 프로그램은 사용할 하드웨어를 직접 특정 드라이버와 연결해야 하며, 그렇지 않으면 프로그램이 외부 장치를 전혀 사용할 수 없다.
    - print 함수를 사용하려면 직접 구현해야 한다. 최신 운영 체제는 유용한 라이브러리를 다양하게 제공한다.
    - 아름다운 상호 작용 인터페이스(interactive interface)를 원한다면 직접 구현해야 한다.
- CPU는 한 번에 한 가지 일만 할 수 있다. 따라서 프로그램 A의 기계 명령어를 실행하거나 프로그램 B의 기계 명령어를 실행하는 것 중 하나만 할 수 있다. 
  - 프로그램 A와 B가 동시에 실행되는 것처럼 보이게 하는 방법: CPU는 먼저 프로그램 A를 실행했다가 이를 잠시 중지하고 프로그램 B의 실행으로 넘어간다. 그리고 프로그램 B를 실행했다가 이를 잠시 중지하고 다시 프로그램 A의 실행으로 돌아갈 수 있다. 이 때 CPU의 전환 빈도가 충분히 빠르다면 '동시에 실행'되는 것처럼 보인다.
  - 일시 중지했다가 다시 재개할 때 중요한 점은 상태가 유지되고, 유지되었던 상태를 이용하여 다시 재개해야 한다. 이때 저장되는 상태를 상황 정보(context)라고 한다.
  - 프로그램 실행 상태를 저장하고 복구할 때 사용할 구조체(structure)의 이름이 프로세스(process)다.
  - **이제 모든 프로그램은 실행된 후 프로세스 형태로 관리**된다.
- 프로그램을 자동으로 적재해 주는 적재 도구와 멀티태스킹을 실현해 주는 프로세스 관리 도구와 같이 여러 가지 기반 기능의 프로그램을 모아 둔 도구에 이름이 운영 체제(operating system)다.
  - 운영 체제가 탄생하면서 프로그래머는 더 이상 실행 파일을 수동으로 적재하거나 프로그램을 수동으로 유지 관리할 필요가 없어졌다. 모든 것을 운영 체제에 맡기기만 하면 된다.
  - 최신 운영 체제는 시스템에서 실제로 실행 중인 타 프로세스가 몇 개인지, CPU가 몇 개인지, 물리 메모리의 용량이 얼마인지 신경 쓰지 않고 간단하게 내가 지금 사용하는 프로그램이 CPU와 표준 크기의 메모리를 독점하고 있다고 생각할 수 있다.
- 고급 프로그래밍 언어, 컴파일러, 링커, 운영 체제는 철저하게 프로그래머의 생산성을 발휘할 수 있게 도와주는 초석에 해당하는 소프트웨어 제품군이다.

#### 프로세스는 매우 훌륭하지만, 아직 불편하다 

- 운영 체제의 가상 메모리는 각각의 프로세스가 표준적인 메모리 크기를 독점적으로 사용하는 것처럼 보이게 한다.
- 프로세스 주소 공간(process address space): 주소 공간이라고도 한다. 위에서 아래 방향으로 다음과 같다.
  - 스택 영역(stack segment): 함수의 실행 시간 스택
  - 힙 영역(heap segment): malloc 함수가 요청을 반환한 메모리가 여기에 할당
  - 데이터 영역(data segment): 전역 변수 등이 저장됨
  - 코드 영역(code segment): 코드를 컴파일하여 생성된 기계 명령어가 저장됨
- funcA와 funcB가 독립적일 때, 전체 실행 속도를 높이는 방법
  - 프로세스 A, B를 생성하여 각각 funcA와 funcB의 결과를 얻은 후 프로세스 B의 결과를 프로세스 A로 전달(프로세스 간 통신, IPC)하여 값 두 개를 더하는 것이다.
  - 이것이 바로 다중 프로세스 프로그래밍(multi-process programming)이다.
    - 다중 프로세스 프로그래밍의 단점
      - 프로세스를 생성할 때 비교적 큰 부담(overhead)이 걸린다.
      - 프로세스마다 자체적인 주소 공간을 가지고 있기 때문에 프로세스 간 통신은 프로그래밍하기에 더 복잡하다.
  
#### 프로세스에서 스레드로 진화

- 프로세스의 주소 공간에는 CPU가 실행하는 기계 명령어와 함수가 실행될 때 스택 정보가 저장된다. 프로세스를 실행하려면 main 함수의 첫 번째 기계 명령어 주소를 PC 레지스터에 기록해야 한다. 이 과정을 거치면 명령어 실행 흐름이 형성된다.
- main 함수와 다른 함수 간에 차이점은 없다. main 함수는 프로그램이 시작할 때 CPU가 실행하는 첫 번째 함수라는 점에서 특별하지만, 그 외에 특별할 것이 전혀 없다. PC 레지스터가 main 함수를 가리키게 할 수 있듯이 다른 어떤 함수라도 가리키게 할 수 있으며, 이를 통해 새로운 실행 흐름을 형성할 수 있다.
- 중요한 점은 이런 실행 흐름이 동일한 프로세스 주소 공간을 공유하므로, 더 이상 프로세스 간 통신이 필요하지 않다는 것이다.
- 하나의 프로세스에 진입 함수가 두 개 이상 있을 수 있음을 알았고 하나의 프로세스에 속한 기계 명령어를 CPU 여러 개에서 동시에 실행할 수 있다.
- 공유 프로세스 주소 공간에서 동일한 프로세스에 속한 명령어를 동시에 실행할 수 있다. 다시 말해 하나의 프로세스 안에 여러 실행 흐름이 존재할 수 있다. 이것을 스레드(thread)라고 한다.
- 스레드 두 개를 생성하고, funcA와 funcB를 각각 구분해서 실행한 후 결과를 전역 변수에 저장하고, 마지막으로 이 값을 서로 더하는 방식으로 funcA와 funcB를 동시에 스레드 두 개에서 실행할 수 있다. 
  - 이상적인 상황에서 이 스레두 두 개가 CPU 코어 두 개에서 동시에 실행된다고 가정하면, 전체 프로그램의 실행 시간은 더 오래 실행되는 함수에 따라 달라진다.
  - 여기에서 두 값을 더하는 과정에서 프로세스 간 통신이 일어나지 않는다. 심지어 스레드 사이에는 근본적으로 통신이라는 개념이 존재하지 않는데, 변수가 다중 프로세스 프로그래밍 때처럼 더 이상 서로 다른 주소 공간이 아닌 동일한 프로세스 주소 공간에 속해 있기 때문이다.
- 스레드가 자신이 속해 있는 프로세스의 주소 공간을 공유한다는 의미이며, 이는 스레드가 프로세스보다 훨씬 가볍고 생성 속도가 빠른 이유이기도 하다. 이런 이유로 스레드를 경량 프로세스(light weight process, LWP)라고 한다.
- 스레드라는 개념이 생겼으니, 이제 프로세스를 시작하고 스레드 여러 개를 생성하기만 하면 다중 코어를 충분히 이용하여 모든 CPU를 최대한 활용할 수 있다. 이것이 바로 고성능과 높은 동시성의 기초가 된다.
- 다중 코어가 있어야만 다중 스레드(multi-threading)를 사용할 수 있는 것은 아니며, 단일 코어인 상황에서도 스레드 여러 개를 생성할 수 있다. 이는 스레드가 운영 체제 계층에 구현되며 코어 개수와는 무관하기 때문이다.
  - 활용 예: 특정 이벤트 처리하는데 많은 시간이 필요하여 응답이 없는 상황을 방지하고자 해당 이벤트를 처리하는 별도의 스레드를 생성할 수 있다.
- 스레드의 단점
  - 다중 스레드가 공유 리소스에 접근할 때 오류가 발생할 수 있다.
  - 따라서 프로그래머는 상호 배제(mutual exclusion)와 동기화(synchronization)를 이용하여 다중 스레드 공유 리소스 문제를 명시적으로 직접 해결해야 한다.

#### 다중 스레드와 메모리 구조

- 함수가 실행될 때 필요한 정보에는 함수의 매개변수(parameter), 지역 변수, 반환 주소(return address) 등이 있다. 이런 정보는 대응하는 스택 프레임(stack frame)에 저장되며, 모든 함수는 실행 시에 자신만의 실행 시간 스택 프레임(runtime stack frame)을 가진다.
- 함수가 호출되고 반환될 때마다 이 스택 프레임은 후입선출(last in first out) 순서로 증가하거나 감소하며, 이런 스택 프레임의 증감이 프로세스 주소 공간에서 스택 영역을 형성한다.
- 스레드라는 개념이 존재하기 전에는 프로세스 내에 실행 흐름이 단 하나만 존재했었고, 스택 영역도 하나만 있었다.
- 스레드를 사용한 이래 하나의 프로세스에 실행 진입점(execution entry point)이 여럿 존재할 수 있게 되었고, 동시에 실행 흐름도 여러 개 존재할 수 있다. 각 흐름이 실행될 때 정보를 저장하기 위해 스택 영역이 여러개 필요해졌다. 또 프로세스의 주소 공간에 각 스레드를 위한 스택 영역이 별도로 있어야 한다.
- 즉, 모든 스레드는 각자 자신만의 스택 영역을 가지는데, 스레드가 이를 인지하는게 중요하다.
- 프로세스 주소 공간에 스레드를 생성하면, 프로세스의 메모리 공간이 소모된다.

#### 스레드 활용 예

- 수명 주기(lifecycle) 관점에서 볼 때, 스레드가 처리해야 하는 작업에는 긴 작업(long task)과 짧은 작업(short task)이라는 두 가지 유형이 있다.
- 긴 작업에는 전용 스레드를 생성하는 것이 가장 적합하며, 사실 이런 상황은 비교적 간단하다.
- 짧은 작업이란 네트워크 요청, 데이터베이스 쿼리 처리 시간 등이 있다. 따라서 짧은 작업은 웹 서버, 데이터베이스 서버, 파일 서버, 메일 서버 등 각종 서버에서 많이 볼 수 있다.
  - 이런 상황에는 두 가지 특징이 있는데, 하나는 작업 처리에 필요한 시간이 짧다는 것이다. 다른 하나는 작업 수가 엄청나게 많다는 것이다.
- 서버가 하나의 요청을 받으면 해당 작업을 처리하는 스레드를 생성하고 처리가 완료되면 스레드를 종료하면 된다고 간단하게 생각할 수 있다.
  - 이 방법은 일반적으로 요청당 스레드(thread-per-request)라고 한다.
  - 긴 작업을 대상으로는 매우 잘 동작하고 구현이 간단하다. 하지만 대량의 짧은 작업에서는 다음 몇 가지 단점이 있다.
    - 스레드의 생성과 종료에 많은 시간을 허비한다.
    - 스레드마다 각자 독립적인 스택 영역이 필요한데, 많은 수의 스레드를 생성하면 메모리와 기타 시스템 리소스를 너무 많이 소비한다.
    - 스레드 수가 많으면 스레드 간 전환에 따른 부담이 증가한다.
- 예를 들어 공장의 사장이고, 주문이 매우 많은 상황에 비유할 수 있다. 주문 하나가 새로 추가될 때마다 새로운 근로자를 고용한다. 주문 처리가 완료되면 근로자를 해고하고, 새로운 주문이 들어오면 다른 근로자를 고용한다. 한 번 근로자를 고용한 후 써먹고 나면 바로 해고하는 대신 주문이 들어오면 주문을 처리하고 없을 때 휴식하는 것이 훨씬 더 나은 전략이다.
- 이것이 바로 스레드 풀(thread pool)이 탄생하게 된 이유이다.

#### 스레드 풀의 동작 방식

- 스레드 풀의 개념은 매우 간단하다. 단지 스레드 여러 개를 미리 생성해 두고, 스레드가 처리할 작업이 생기면 해당 스레드에 처리를 요청하는 것이다.
- 스레드 여러 개가 미리 생성되어 있기 때문에 스레드 생성과 종료 작업이 빈번하게 발생하지 않으며, 이와 동시에 스레드 풀 내에 있는 스레드 수도 일반벅으로 일정하게 관리되기 때문에 불필요하게 많은 메모리를 소비하지 않는다. 이 개념에서 중요한 점은 스레드를 재사용하는 것이다.
- 이런 시나리오에 적합한 것은 자료 구조(data structure)의 대기열(queue)이다. 작업을 전달하는 것은 생산자(producer)이며, 작업을 처리하는 스레드는 소비자(consumer)이다. 고전적인 생산자-소비자 패턴(producer-consumer pattern)이다.
- 스레드 풀에 전달되는 작업은 '처리할 데이터'와 '데이터를 처리하는 함수' 두 부분으로 구성된다.
- 스레드 풀의 스레드는 작업 대기열(jobs queue)에서 블로킹 상태로 대기한다. 생산자가 작업 대기열에 데이터를 기록하면 스레드 풀의 스레드가 깨어나고, 깨어난 스레드는 작업 대기열에서 처리 함수(handler function)를 실행한다.
- 작업 대기열은 여러 스레드 간에 공유되는 리소스이므로 동기화를 할 때 상호 배제(mutual exclusion in synchronization) 문제도 반드시 처리해야 한다.

#### 스레드 풀의 스레드 수

- 스레드 풀의 수가 너무 적다면 CPU를 최대한 활용할 수 없으며, 너무 많은 스레드를 생성하면 반대로 시스템 성능 저하, 메모리의 과다한 점유, 스레드 전환으로 생기는 부담 등 문제가 발생한다.
- 긴 작업과 짧은 작업으로 분류한 것은 수명 주기 관점에서 작업을 구분한 것이다. 작업을 처리할 때 필요한 리소스 관점에서 구분하자면, CPU 집약적인 작업(CPU intensive task)와 입출력 집약적인 작업(input/output intensive task)으로 구분할 수 있다.
- CPU 집약적인 작업이란 과학 연산, 행렬 연산 등 작업을 처리할 때 외부 입출력에 의존할 필요 없이 처리할 수 있는 작업을 의미한다. 이 경우 스레드 수와 CPU 코어 수가 기본적으로 동일하다면 CPU의 리소스를 충분히 활용할 수 있다.
- 입출력 집약적인 작업이란 연산 부분이 차지하는 시간은 많지 않은 대신 대부분의 시간을 디스크 입출력이나 네트워크 입출력 등에 소비하는 작업을 의미한다. 이 경우 필요한 스레드 수의 계산은 성능 테스트 도구를 사용하여 입출력 대기 시간(WT, wait time)과 CPU 연산에 필요한 시간(CT, computing time)을 평가해야 한다. N개의 코어를 가진 시스템에서 적절한 스레드 수는 대략 N * (1 + WT / CT)이며, WT와 CT가 동일하다고 가정하면 대략 2N개의 스레드가 있어야 CPU 리소스를 최대한 활용할 수 있다. 하지만 이론적인 값에 불과하며, 실제 상황을 기반으로 테스트를 실시하여 필요한 스레드 수를 결정하길 추천한다.

### Section 2.2 스레드 간 공유되는 프로세스 리소스

- 프로세스와 스레드의 차이는? 프로세스는 운영 체제가 리소스를 할당하는 기본 단위고, 스레드는 스케줄링(scheduling)의 기본 단위며, 프로세스 리소스는 스레드 간에 공유된다.

#### 스레드 전용 리소스(thread-private resource)

- 상태 변화 관점에서 보면 스레드는 사실 함수 실행이다. CPU는 진입 함수에서 실행을 시작하여 하나의 실행 흐름을 생성하는데, 이 실행 흐름에 인위적으로 스레드라는 이름을 붙인 것에 불과하다.
- 함수의 실행 시간 정보는 스택 영역을 구성하는 스택 프레임에 저장된다. 이때 스택 프레임에 함수의 반환값, 다른 함수를 호출할 때 전달되는 매개변수, 함수 내에서 사용되는 지역 변수와 레지스터 정보가 저장된다.
- 각 스레드는 자신만 사용할 수 있는 스택 영역을 가지므로 스레드 여러 개가 있을 때는 여러 스택 영역이 존재한다.
  - 이외에도 다음에 실행될 명령어 주소를 저장하는 PC 레지스터(register), 스레드 스택 영역에서 스택 상단(stack top) 위치를 저장하는 스택 포인터(stack pointer) 등 CPU가 기계 명령어를 실행할 때 내부 레지스터 값도 스레드의 현재 실행 상태에 속한다. 이런 레지스터 정보도 역시 스레드 전용으로, 다른 스레드에서는 이런 레지스터 정보에 접근할 수 없다.
  - 이런 정보를 통틀어 스레드 상황 정보(thread context)라고 한다.
- 스레드는 프로세스 주소 공간에서 스택 영역을 제외한 나머지 영역을 모두 공유한다.

#### 코드 영역: 모든 함수를 스레드에 배치하여 실행할 수 있다

- 프로세스 주소 공간의 코드 영역에는 프로그래머가 작성한 코드가 저장된다. 이 영역은 모든 스레드가 공유하는 역역이다.
- 코드 영역은 스레드 간에 공유되므로 어떤 함수든지 모두 스레드에 적재하여 실행할 수 있고, 특정 함수를 특정 스레드에서만 실행되도록 하는 것은 불가능하다.
- 코드 영역은 읽기 전용(read-only)이기 때문에 프로그램이 실행되는 동안에는 어떤 스레드도 코드 영역 내용을 변경할 수 없다.
- 따라서 프로세스 내 모든 스레드가 코드 영역을 공유하고 있지만, 코드 영역에 관해서는 스레드 안전 문제(thread safety issue)가 발생하지 않는다.

#### 데이터 영역: 모든 스레드가 데이터 영역의 변수에 접근할 수 있다

- 데이터 영역은 전역 변수가 저장되는 곳이다.
- 프로그램이 실행되는 동안 데이터 영역 내에 전역 변수 인스턴스(instance, 특정 데이터 정의 따라 메모리상에 저장된 실체)는 하나만 있기 때문에 모든 스레드는 이 전역 변수에 접근할 수 있다.

#### 힙 영역: 포인터가 핵심이다

- C/C++ 언어에서 malloc 함수와 new 예약어로 요청하는 메모리가 이 영역에 할당된다.
- 모든 스레드는 해당 변수 주소만 알고 있다면, 다시 말해 포인터(pointer)를 얻을 수 있다면 포인터가 가리키는 데이터에 접근할 수 있다.
- 따라서 힙 영역은 스레드 간 공유 리소스이다.

#### 스택 영역: 공유 공간 내 전용 데이터

- 서로 다른 프로세스의 주소 공간은 서로 격리되어 있으며, 가상 메모리 시스템은 매우 특별한 경우를 제외하고 다른 프로세스의 주소 공간에 속한 데이터에 직접 접근하지 못하도록 보장한다.
- 하나의 스레드가 다른 스레드의 스택 프레임에서 포인터를 가져올 수 있다면 해당 스레드는 다른 스레드의 스택 영역을 직접 읽고 쓸수 있다. 즉, 다른 스레드의 스택 영역에 속한 변수를 임의로 수정할 수 있음을 의미한다.
- 어떤 면에서 프로그래머에게는 매우 편리하지만, 그와 동시에 해결이 매우 어려운 버그(bug)로 이어질 수 있다.
- 비록 스택 영역은 스레드 전용 데이터에 속하지만, 스택 영역에는 별도의 보호를 위한 작동 방식이 존재하지 않기 때문에 다른 스레드에서 특정 스레드의 스택 영역의 데이터를 읽고 쓸 수 있다.

#### 동적 링크 라이브러리와 파일

- 정적 링크는 종속된 모든 라이브러리가 실행 파일에 포함되는 것을 의미한다. 이와 같은 프로그램의 실행 파일에는 모든 코드와 데이터가 포함되어 있기 때문에 프로그램을 시작할 때 추가적인 작업이 필요하지 않다.
- 동적 링크에는 실행 파일에 종속된 라이브러리의 코드와 데이터가 포함되어 있지 않기 때문에 프로그램을 시작할 때 또는 실행 중일 때 종속된 라이브럴의 코드와 데이터를 찾아서 프로세스 주소 공간에 넣는 링크 과정이 완료되어야 한다.
  - 주소 공간에서 이 부분은 모든 스레드가 공유한다. 즉, 프로세스 내 모든 스레드가 동적 라이브러리 코드의 데이터를 사용할 수 있다.
- 프로그램이 동작 중에 특정 파일을 열면 프로세스 주소 공간에 열린 파일 정보도 저장된다. 프로세스가 연 파일 정보는 모든 스레드에서 사용할 수 있으며, 이것 역시 스레드 간 공유 리소스에 속한다.

#### 스레드 전용 저장소(thread local storage)

- 스레드 전용 저장소에 저장되는 변수는 다음과 같은 두 가지 의미가 있다.
  - 이 영역에 저장된 변수는 모든 스레드에서 접근할 수 있다.
  - 모든 스레드가 동일한 변수에 접근하는 것처럼 보일 수 있지만, 사실 변수의 인스턴스는 각각의 스레드에 속한다. 따라서 하나의 스레드에서 변수 값을 변경해도 다른 스레드에는 반영되지 않는다.
- 스레드 전용 저장소를 사용하면 각각의 스레드에서 독점적으로 변수를 사용할 수 있다. 즉, 이 변수들은 모든 스레드에서 접근할 수 있지만 해당 변수는 초기화한 후 각각의 스레드가 복사본을 가지게 되며, 하나의 스레드에서 변수 값을 변경하더라도 다른 스레드에는 영향을 미치지 않는다.

### Section 2.3 스레드 안전 코드는 도대체 어떻게 작성해야 할까?

#### 자유와 제약

- 스레드가 자신만의 전용 데이터를 사용한다면 스레드는 안전하다. 이런 데이터에는 함수의 지역 변수와 스레드 전용 저장소 등이 있다.
- 스레드가 공유 리소스를 사용할 때는 반드시 그에 상응하는 제약이 필요하며, 특정 스레드가 다른 스레드의 공유 리소스 사용 순서를 방해하지 않는 한 스레드 안전을 달성할 수 있다. 
- 정리하면,
  - 전용 리소스를 사용하는 스레드는 스레드 안전을 달성할 수 있다.
  - 공유 리소스를 사용하는 스레드는 다른 스레드에 영향을 주지 않도록 하는 대기 제약 조건에 맞게 공유 리소스를 사용하면 스레드 안전을 달성할 수 있다.

#### 스레드 안전이란 무엇일까?

- 어떤 코드가 주어졌을 때, 그 코드가 스레드 몇 개에서 호출되든 이 스레드들이 어떤 순서로 호출되든 간에 상관없이 올바른 결과가 나온다면, 이 코드를 스레드 안전이라고 말한다.
- 공유 리소스: 정수처럼 단순한 변수일 수도 있고 구조체처럼 데이터일 수도 있다. 가장 중요한 점은 이런 리소스를 여러 리소스에서 읽고 쓸 수 있어야 한다는 것이며, 이 조건을 만족해야만 공유 리소스라고 할 수 있다.

#### 스레드 전용 리소스와 공유 리소스

- 스레드 전용 리소스: 함수의 지역 변수, 스레드의 스택 영역, 스레드 전용 저장소
- 공유 리소스: 그 외의 영역, 주로 힙 영역과 데이터 영역으로 구성
- 공유 리소스를 사용하는 스레드는 반드시 순서를 따라야 하며, 이 순서 핵심은 공유 리소스를 사용하는 다른 작업이 다른 스레드를 방해할 수 없다는 것이다. 그리고 이를 위해 각종 잠금(lock)이나 세마포어(semaphore) 같은 장치를 사용할 수 있다. 이 규칙의 목적은 공유 리소스 순서를 유지하는 것이다.

#### 스레드 전용 리소스만 사용하기

```c
int func() {
  int a = 1;
  int b = 1;
  return a + b;
}
```

- func 함수는 몇 개의 스레드에서 호출하든 어떻게 호츨하든 언제 호출하든 상관없이 언제나 정확하게 2를 반환한다.
- 이 함수는 어떤 전역 변수나 매개변수에 의존하지 않고 오로지 스레드 전용 리소스인 지역 변수만 사용하는데, 이런 변수는 스레드 스택 영역에서 관리한다.
- 이런 코드를 무상태 함수(stateless function)라고도 하며, 이런 코드가 스레드 안전이라는 것은 분명하다.

#### 스레드 전용 리소스와 함수 매개변수

- 함수에 매개변수를 값으로 전달(call by value)하는 경우라면 문제없으며, 여전히 스레드 안전하다. 이유는 간단하다. 값으로 전달된 매개변수도 스레드 전용 리소스이며, 이 매개변수들도 스레드 자신만의 스택 영역에 저장되기 때문이다.
- 하지만 포인터를 전달하면 더 이상 스레드 안전이 아니다.
- 스레드 안전인 코드를 작성하는 원칙 중 하나는 스레드 간에 공유 리소스를 사용하지 않도록 가능한 한 모든 조치를 취하는 것이다.

#### 전역 변수 사용

- 만약 사용되는 전역 변수가 처음 프로그램이 실행될 때 한 번 초기화되고 나서 모든 코드가 이 변수를 읽기만 한다(마치 전역 변수가 상수처럼 사용)면 문제없다.
- 읽기 전용 전역 변수는 스레드 안전인 공유 리소스
- 읽고 쓰기 가능한 전역 변수는 스레드 안전이 아닌 공유 리소스

#### 스레드 전용 저장소

- 스레드 전용 저장소에 배치된 변수는 스레드 안전이다.

#### 함수 반환값

- 함수가 값을 반환하는 경우(return by value): 스레드 안전
- 함수가 포인터를 반환하는 경우(return by reference): 스레드 안전이 아님

#### 스레드 안전이 아닌 코드 호출하기

- 스레드 안전이 아닌 func 함수가 있다. 이 함수를 호출하기 전에 잠금으로 보호하면 스레드 안전이다. 이유는 잠금으로 전역 변수를 간접적으로 보호하기 때문이다.

```c
int funcA() {
  mutex l;
  l.lock();
  func();  // 스레드 안전이 아닌 함수
  l.unlock();
}
```

- 이 코드를 살펴보자. 매개변수로 전달된 포인터가 전역 변수를 가리키는지 아닌지 알 수 없기 때문에 일반적으로 func 함수가 스레드 안전이 아니라고 생각한다.

  ```c
  int func(int *num) {
    ++(*num);
    return *num;
  }
  ```

  - 하지만 다음과 같이 호출한다면, funcA 함수는 스레드 안전하다. 전달된 매개변수가 스레드 전용 리소스인 지역 변수이기 때문에 funcA 함수를 호출하는 스레드가 몇 개든 서로 간섭하지 않는다.

  ```c
  void funcA() {
    int a = 100;
    int b = func(&a);
  }
  ```

#### 스레드 안전 코드는 어떻게 구현할까?

- 스레드 간에 어떤 공유 리소스도 읽거나 쓰지 않는다면 스레드 안전 문제는 있을 수 없다. 공유 리소스가 어느 영역에 저장되어 있든 관계없이 다중 스레드 프로그래밍 중에는 어떤 리소스라도 최대한 공유하지 않는 것이 원칙이다.
- 처리해야 할 작업이 스레드 사이에서 어떤 종류의 리소스를 공유해야 한다면 반드시 코드의 스레드 안전에 주의를 기울여야 한다.
- 스레드 안전을 달성하려면 어떤 것이 스레드 전용 리소스고 어떤 것이 스레드 공유 리소스인지 파악할 필요가 있다.
  - 스레드 전용 저장소(thread local storage): 전역 리소스를 사용해야 하는 경우 스레드 전용 저장소로 선언할 수 있는지 확인해 본다. 모든 스레드에서 사용할 수 있지만 각 스레드마다 자체 복사본이 있으며, 이를 변경하더라도 다른 스레드에 영향을 미치지 않기 때문이다.
  - 읽기 전용(read-only): 전역 리소스를 반드시 사용해야 한다면 해당 전역 리소스를 읽기 전용으로 사용해도 되는지 확인한다. 다중 스레드에서 읽기 전용 전역 리소스를 사용하더라도 스레드 안전 문제가 발생하지 않는다.
  - 원자성 연산(atomic operation): 원자성 연산은 도중에 중단되지 않는다. 따라서 이런 변수에 대한 연산에는 전통적인 방식의 잠금으로 보호가 필요하지 않다.
  - 동기화 시 상호 배제(mutual exclusion in synchronization): 이 단계까지 내려왔다면, 한 번에 하나의 스레드만 공유 리소스에 접근할 수 있도록 스레드가 접근하는 공유 리소스 순서를 프로그래머가 어쩔 수 없이 직접 유지해야 하는 상황까지 내몰린 것이다. 뮤텍스(mutex), 스핀 잠금(spin lock), 세마포어(semaphore) 외에 여러 가지 동기화 시 상호 배제를 위한 작동 방식 모두가 이 목적을 이루는 데 사용될 수 있다.

- 지금까지 말하는 스레드는 기본적으로 커널 스레드(kernel thread)를 의미한다. 커널 스레드의 생성, 스케줄링, 종료를 모두 운영 체제가 수행한다. 즉 프로그래머가 스레드가 어떻게 생성되고 스케줄링되는지 전혀 관여할 수 없다는 의미다.
- 운영 체제에 의존하지 않는 상황에서 직접 스레드를 구현할 수 있을까? 가능하다. 바로 스레드보다 더 가벼운 실행 흐름인 코루틴으로 구현할 수 있다.

### Section 2.4 프로그래머는 코루틴(coroutine)을 어떻게 이해해야 할까?

#### 일반 함수

```python
def func():
  print("a")
  print("b")
  print("c")

def foo():
  func()
```

#### 일반 함수에서 코루틴으로

- 코루틴에는 스레드와 유사한 기능인 일시 중지와 재개 기능이 있다.
- 코루틴은 자신의 실행 상태를 저장할 수 있기 때문에 코루틴이 반환된 후에도 계속 호출이 가능하며, 더군다나 마지막으로 일시 중지된 지점에서 다시 이어서 실행된다는 점이 놀랍다. 호출한 쪽에서 다시 코루틴을 호출할 때마다 해당 코루틴은 이전에 반환되었던 지점부터 다시 계속 실행되므로 `print("b")`가 실행된다.

```python
def func():
  print("a")
  yield  # 멈춰라
  print("b")
  yield  # 멈춰라
  print("c")
```

- 일반 함수는 반환된 후 프로세스 주소 공간의 스택 영역에 더 이상 어떤 함수 실행 시 정보도 저장하지 않는다.
- 하지만 코루틴이 반환될 때는 함수의 실행 시 정보를 저장할 필요가 있는데, 코루틴이 실행이 멈추었던 지점에서 다시 실행할 때 이 정보가 필요하기 때문이다.
- 위의 코루틴을 사용하는 방법

```python
def A():
  co = func()  # 코루틴 획득
  next(co)  # 코루틴 호출 
  print("in function A")  # 작업 실행
  next(co)  # 코루틴 재호출

""" 결과
a
in function A
b
"""
```

#### 직관적인 코루틴 설명

- 일반 함수 호출의 실행 흐름: 먼저 funcA 함수에 도착하여 일정 시간을 실행하다가 도중에 또다른 함수 funcB의 실행 코드를 발견한다. 이 때 제어권은 funcB로 넘어가며 함수 실행이 완료되면 funcA 함수의 호출 지점으로 돌아가서 실행을 계속한다.
- 코루틴 호출의 실행 흐름: funcA 함수는 어느 정도 실행되다가 코루틴을 실행한다. 코루틴이 시작되면 첫 번째 연결 시작 지점까지 실행하다가 funcA 함수로 돌아간다. funcA 함수는 이어서 실행되다 다시 해당 코루틴을 실행한다. 코루틴은 이때부터 일반 함수와 달라지는데, 코루틴은 첫 번째 줄의 코드부터 실행되는 것이 아니라 앞의 연결 시작 지점부터 실행된다. 코루틴은 다시금 두 번째 연결 시작 지점을 만나고, funcA 함수로 돌아간다. 마지막으로 funcA 함수의 나머지 부분이 실행되고 전체 프로그램이 종료된다.

#### 함수는 그저 코루틴의 특별한 예에 불과하다

- 코루틴은 자신이 일시 중지될 때 실행 중인 상태를 저장했다가 저장되었던 상태에서 다시 시작하여 계속 실행된다.
- 운영 체제가 스레드를 스케줄링하는 것과 똑같다. 스레드도 일시 중지될 수 있으며, 운영 체제가 먼저 스레드의 실행 상태를 저장했다가 다른 스레드의 스케줄링을 진행한다. 그리고 일시 중지된 스레드가 다시 CPU의 리소스를 할당받으면 스레드는 마치 일시 중지된 적이 없는 것처럼 이어서 실행한다.
- 컴퓨터 시스템은 주기적으로 타이머 인터럽트(timer interrupt)를 생성하고, 인터럽트가 처리될 때마다 운영체제는 현재 스레드의 일시 중지 여부를 결정할 기회를 가진다. 이것이 바로 프로그래머가 명시적으로 스레드를 언제 일시 중지시키고 CPU의 리소스를 내어 줄지 지정할 필요가 없는 이유다.
- 그러나 사용자 상태(user mode)에서는 타이머 인터럽트를 위한 작동 방식이 없기 때문에 코루틴에서 반드시 yield와 같은 예약어를 사용하여 어디에서 일시 중지하고 CPU의 리소스를 내어 줄 것인지 명시적으로 지정해야 한다.
- 반드시 유일한 점은 코루틴 몇 개를 생성하든 관계없이 운영 체제는 이를 알지 못한다. 코루틴은 온전히 사용자 상태 내에서 구현된 것이기 때문에 코루틴을 사용자 상태 스레드로 해석할 수 있다.

#### 코루틴의 역사

- 코루틴 개념은 1958년에 이미 존재했다. 이는 스레드 개념이 나타나기도 전이다.
- 스레드가 없었기 때문에 동시성을 가지는 프로그램을 작성하려면 어쩔 수 없이 코루틴과 같은 기술을 사용할 수 밖에 없었다.
- 이후 스레드가 등장하고 운영 체제가 기본적으로 프로그램의 동시 실행을 지원하기 시작하면서 코루틴은 프로그래머 기억 속에서 조용히 사라졌다.
- 최근 인터넷이 발달하고, 특히 모바일 인터넷 시대가 되면서 서버에서 처리해야 하는 사용자 요청이 기하급수적으로 늘어나기 시작했다. 이런 상황에서 코루틴은 높은 성능과 동시성을 요구하는 분야에서 자신의 위치를 찾게 됐다.
- 많은 주류 프로그래밍 언어가 이미 코루틴을 지원하고 있거나 앞으로 지원할 계획이다.

#### 코루틴은 어떻게 구현될까?

- 코루틴의 구현은 사실 스레드의 구현과 본질적으로 차이가 없다.
- 코루틴은 일시 중지되거나 다시 시작될 수 있으며, 일시 중지될 때의 상태 정보를 반드시 기록해야 한다. 이를 기반으로 코루틴을 다시 시작해야 한다.
- 상태 정보에는 'CPU의 레지스터 정보', '함수 실행 시 상태 정보'가 포함된다. 이는 주로 함수의 스택 프레임에 저장된다.
- 프로세스 주소 공간의 스택 영역은 스레드를 위한 공간이다. 코루틴의 스택 프레임 정보는 어디에 저장해야 할까? 힙 영역에 코루틴의 실행 시간 스택 프레임 정보를 저장하는 메모리를 요청할 수 있다.
- 프로세스 주소 공간의 최상단에 있는 스택 영역의 역할은? 함수 스택 프레임을 보관하는데 사용된다. 단지 이 함수들이 코루틴이 아닌 일반 함수라는 차이가 있다.
- 이론적으로 메모리 공간이 충분하다면 코루틴 개수에 제한은 없으며 코루틴 간 전환이나 스케줄링은 전적으로 사용자 상태에서 일어나기 때문에 운영 체제가 개입할 필요가 없다. 
- 또 코루틴 간에 전환할 때 저장 또는 복구되는 정보도 더 가볍기 때문에 효율성도 훨씬 높다.
- 코루틴의 중요한 역할 중 하나는 바로 프로그래머가 동기 방식으로 비동기 프로그래밍을 가능하게 한다는 것이다.

### Section 2.5 콜백 함수(callback function)를 철저하게 이해한다

#### 모든 것은 다음 요구에서 시작된다

- A팀과 B팀이 같이 앱을 개발한다고 가정한다. 이 중에서 핵심 모듈(core module)은 B팀이 개발하고 A팀에서는 이를 호출한다. 이 핵심 모듈은 make_donut이라는 함수에 담겨(encapsulation) 있다.
- make_donut 함수에서 비교적 중요한 부분은 도넛 모양을 형성하는 것으로 이는 formed 함수로 구현한다.
- 사업 규모가 확장되 C팀에서도 이 함수를 사용하고 싶어한다. 하지만 C팀에서는 기존 막대 형태의 도넛 대신 원형의 도넛을 이용한 사업을 모색하고 있기 때문에 formed 함수는 A팀과 C팀 양쪽에서 모두 사용할 수 있도록 수정되야 한다.
- if else 문 추가
- 사업이 큰 성공을 거두어, 전 세계적인 인기를 끌게 되었다. 자국 국민의 습관에 따라 현지화(localization)을 거쳐 다양한 도넛 모양을 만들어야 한다.
- if else 문이 수천 개 필요할 뿐만 아니라, 새로운 현지화 요청이 있을 때마다 make_donut 함수를 수정해야 한다.

```c
void make_donut() {
  // ...
  if (teamA) { form_a(); }
  else if (teamC) { form_b(); }
  else if (teamD) { ... }
  // ...
}
```

#### 콜백이 필요한 이유

- 프로그래머는 코드를 작성할 때 변수를 자주 사용한다. 그렇지 않으면 코드 전체에서 모두 찾아서 전부 바꾸어야 한다.
- 사실은 함수를 변수처럼 사용할 수 있다.

```c
void make_donut(func f) {
  // ...
  f();
  // ...
}
```

- make_donut 함수를 사용하고 싶은 프로그래머는 자신이 정의한 현지화 함수를 전달만 하면 되므로, 함수 변수로 한 번에 문제를 해결 할 수 있다.
- **함수 변수를 콜백 함수**라고 부른다.

```c
void formed_c() {}

make_donut(formed_c);
```

- 일반적으로 콜백 함수 코드는 직접 구현한다. 그러나 그 함수를 호출하는 것은 보통 다른 모듈이나 스레드에서 해당 함수를 호출한다.

#### 비동기 콜백

- 사업이 잘되고 주문량이 증가할수록 make_donut 함수의 실행 시간도 점점 더 길어졌다.
- 이 함수를 호출하는 D팀의 코드가 다음과 같이 작성되었다.

```c
// ...
make_donut(formed_d);
something_important();  // 중요 코드
// ...
```

- something_important 함수가 너무 중요해서 오래 대기 할 수 없다면 어떻게 해야할까? make_donut 함수를 다음과 같이 수정하여 해당 함수 내부에서 스레드를 생성하고 해당 스레드가 실제로 도넛을 형성하게 할 수 있다.

```c
void real_make_donut(func f) {
  // ...
  f();
  // ...
}

void make_donut(func f) {
  thread t(real_make_donut, f);
}
```

- make_donut 함수를 호출하면 해당 함수는 새로운 스레드 t를 생성하고 나서 즉시 반환되고, 이후 something_important() 줄을 실행한다.
- 여기에서 주의할 점은 something_important() 줄의 코드가 실행될 때 실제 도넛 생성 작업은 아직 시작되지 않았을 수도 있다는 것이다. 이것이 비동기(asynchronization)이다.
- make_donut 함수를 호출하고 나서 기다릴 필요가 없으며, 호출자와 피호출자가 각자의 스레드에서 병렬로 실행될 수 있다. 이와 같이 스레드가 콜백 함수 실행에 의존하지 않는 것을 비동기 콜백(asynchronization callback)이라고 한다.

#### 비동기 콜백은 새로운 프로그래밍 사고 방식으로 이어진다

- 함수를 호출할 때 프로그래머에게 가장 익숙한 사고 방식은 다음과 같다.
  - 함수를 호출하고 결과를 획득한다.
  - 획득한 결과를 처리한다.
- 이것이 바로 함수의 동기 호출(synchronous call)이다.
- 정보 관점에서 보면, 함수는 사실 호출자가 정보를 채워 넣기 전까지는 매개변수 정보가 무엇인지 알 수 없다. 컴퓨터 관점에서 보면, 정보에는 두 가지 유형이 있다.
  - 첫 번째 유형은 정수, 포인터, 구조체, 객체 등 데이터
  - 두 번째 유형은 함수 같은 코드
- 처리 흐름을 하나의 작업으로 생각할 때, 
  - 동기 호출 프로그래밍 방식에서는 함수를 호출한 스레드에서 전체 작업 처리
  - 비동기 호출 프로그래밍 방식에서는 작업 처리가 두 부분으로 나뉜다.
    - 첫 번째 부분은 함수를 호출하는 스레드에서 처리
    - 두 번째 부분은 함수를 호출하는 스레드에서 처리되지 않고 다른 스레드, 프로세스 또는 다른 시스템에서 처리
  - 두 번째 부분의 호출은 우리가 제어할 수 있는 범위를 벗어나며, 이와 동시에 호출자만 무엇을 해야 할지 알고 있다. 그렇기 때문에 콜백 함수는 꼭 필요한 작동 방식이다.
- 콜백 함수의 본질은 다음과 같다. '우리는 어떤 일을 해야 하는지 알지만, 이 일을 언제 하게 될지는 정확히 알 수 없다. 반면에 다른 모듈은 언제 해야 할지는 알지만 무엇을 해야 하는지는 모르게 때문에 우리가 알고 있는 정보를 콜백 함수에 잘 담아 다른 모듈에 전달해야 한다.'

#### 콜백 함수의 정의 

- 컴퓨터 과학에서 콜백 함수는 다른 코드에 매개변수로 전달되는 실행 가능한 코드이다.
- 일반적으로 함수 작성자가 나라면 함수를 호출하는 것도 나여야 하지만, 콜백 함수는 그렇지 않다. 함수 작성자가 나라도 함수를 호출하는 것은 내가 아니고 내가 참조하는 외부 모듈이다.
- 서드 파티 라이브러리(third party library)를 예로 들면, 내가 서드 파티 라이브러리의 함수를 호출할 때 콜백 함수를 함께 전달하면 서드 파트 라이브러리의 함수는 내가 작성한 콜백 함수를 호출한다. 서드 파티 라이브러리에 콜백 함수를 지정해야 하는 이유는 서드 파티 라이브러리의 작성자가 특정 시기에 어떤 작업을 수행해야 하는지 알 수 없기 때문이다. 서드 파티 라이브러리의 작성자는 특정한 구현 코드를 작성하는 대신 외부와 연결된 매개 변수를 제공한다. 따라서 서드 파티 라이브러리의 사용자가 콜백 함수를 구현해서 서드 파티 라이브러리에 전달하면, 서드 파티 라이브러리는 특정 시기에 해당 콜백 함수를 호출하기만 하면 된다.

#### 두 가지 콜백 유형

- 동기 콜백은 블로킹 콜백(blocking callback)이라고도 한다.
- 비동기 콜백
  - 주 프로그램과 콜백 함수의 실행이 동시에 진행될 수 있기에 보통 주 프로그램과 콜백 함수는 서로 다른 스레드 또는 프로세스에서 실행된다.
  - 지연 콜백(deferred callback)이라고도 한다.
- 비동기 콜백은 동기 콜백에 비해 다중 코어 리소스를 더 잘 활용한다. 동기 콜백이 진행되는 동안에 주 프로그램은 아무 일도 못하지만, 비동기 콜백은 이런 문제없이 주 프로그램을 계속 실행한다.
- 비동기 콜백은 입출력 작업에서 자주 볼 수 있으며, 웹 서비스처럼 동시성이 높은 시나리오에 적합하다.

#### 비동기 콜백의 문제: 콜백 지옥

- 비지니스 구성이 상대적으로 복잡한 경우 서비스 호출을 비동기 콜백으로 처리하면 콜백 지옥(callback hell)에 빠질 가능성이 높다.

- 동기 콜백 방식으로 구현하면 다음과 같다.

```c
a = GetServiceA();
b = GetServiceB();
c = GetServiceC();
d = GetServiceD();
```

- 비동기 콜백 방식으로 구현하면 다음과 같다.

```c
GetServiceA(function(a) {
  GetServiceB(a, function(b) {
    GetServiceC(b, function(c) {
      GetServiceD(c, function(d)) {
        // ...
      }
    })
  })
});
```

- 이처럼 복잡한 비동기 콜백 코드는 주의를 기울이지 않으면 콜백 함정에 빠질 수 있다.
- 비동기 콜백의 효율성, 동기 콜백의 코드 단순성과 가독성을 함께 누릴 수 있는 방법은 바로 코루틴이다.

### Section 2.6 동기와 비동기를 철저하게 이해한다 

- 동기는 '종속적', '연관된', '기다림' 등 단어들과 엮이는 반면에, 비동기는 '비종속적', '무관한', '기다릴필요 없는', '동시 발생' 등 단어들과 엮이는 경우가 많다.

#### 동기 호출 

```c
funcA() {
  // funcB 함수가 완료될 때까지 대기
  funcB();

  // funcB 함수는 프로세스를 반환하고 계속 진행
  // ...
}
```

- 일반적으로 이와 같은 동기 호출에서는 funcA 함수와 funcB 함수가 동일한 스레드에서 실행되는데, 가장 자주 볼 수 있는 상황이다.
- 하지만 비교적 특수한 상황이 하나 있는데 바로 입출력 작업이다.
  - 최하단 계층은 실제로 시스템 호출(system call)로 운영 체제에 요청을 보낸다.
  - 이때 운영 체제는 파일 읽기 작업을 위해 호출 스레드를 일시 중지 시키며, 커널이 디스크 내용을 읽어 오면 일시 중지되었던 스레드가 다시 깨어난다.
  - 이것이 바로 블로킹 입출력(blocking input/output)이다.
  - 물론 이것도 동기 호출이다. 단지 호출자와 파일을 읽는 코드가 다른 스레드에서 실행되고 있을 뿐이다. 
- 따라서 동기 호출은 호출자와 수신자가 같은 스레드에서 실행 중인지 여부와는 관련이 없다.

#### 비동기 호출

- 일반적으로 비동기 호출은 디스크의 파일 읽고 쓰기, 네트워크 데이터 송수진, 데이터베이스 작업처럼 시간이 많이 걸리는 입출력 작업을 백그라운드 형태로 실행한다.
- 예를 들어 디스크 파일을 읽는 작업이 있다.
  - read 함수를 비동기 호출하면 파일 읽기 작업이 완료되지 않은 상태에서도 read 함수는 즉시 반환될 수 있다.
  - 이것이 바로 비동기 입출력이다.
  - 이 경우 호출자가 블로킹되지 않고 read 함수가 즉시 반환되기 때문에 호출자는 즉시 다음 작업을 실행할 수 있다.
- 그러나 비동기 호출은 프로그래머가 이해하는데 큰 부담이 될 수 있으며, 코드를 작성하는 것은 말할 필요도 없다.
- 비동기 호출 방식에서 작업이 실제로 완료되는 시점은 어떻게 파악할까. 이에 대한 처리는 두 가지 상황이 있을 수 있다.
  - 호출자가 실행 결과를 전혀 신경 쓰지 않을 때: 콜백 함수 사용
  - 호출자가 실행 결과를 반드시 알아야 할 때: 알림(notification) 작동 방식을 사용
    - 즉, 작업 실행이 완료되면 호출자에게 작업 완료를 알리는 신호나 메시지를 보내는 것이다.
    - 이 경우 결과 처리는 이전과 마찬가지로 호출 스레드에서 한다.
    - 일반적으로 함수의 비동기 호출에는 흔히 스레드 두 개가 사용되는데, 호출자가 하나의 스레드를 사용하고 실제 작업은 다른 스레드에서 실행된다.

#### 웹 서버에서 동기와 비동기 작업

- 일반적으로 웹 서버는 사용자의 요청을 수신하면 전형적인 과정에 따라 그것을 처리하는데, 그중 가장 자주 볼 수 있는 것은 데이터베이스 요청(database query)이다.
- 데이터베이스 요청을 디스크 읽고 쓰기나 네트워크 통신처럼 다른 입출력 작업이라 가정해도 무방하다.

```c
// 사용자 요청을 처리하는데 필요한 단계
A;
B;
C;
데이터베이스 요청;
D;
E;
F;
```

- 이 중에서 A, B, C, D, E, F 단계에는 입출력 작업이 포함되어 있지 않다. 즉, 파일 읽기나 네트워크 통신 등 작업이 필요없다.
- 동기 방식을 살펴보자. 가장 자연스러우면서 이해하기도 쉽다.

  ```c
  // 메인 스레드
  main_thread() {
    while(1) {
      요청 수신;
      A;
      B;
      C;
      데이터베이스 요청을 전송하고 결과가 반환될 때까지 대기;
      D;
      E;
      F;
      결과 반환;
    }
  }

  // 데이터베이스 스레드
  database_thread() {
    while(1) {
      요청 수신;
      데이터베이스 처리;
      결과 반환;
    }
  }
  ```

  - 데이터베이스 요청 후 주 스레드가 블로킹되어 일시 중지되며, 데이터베이스 처리가 완료된 시점에서 이후 단계인 D, E, F가 계속 실행된다.
  - 주 스레드에 대기 시간이 존재하며, 이것을 유후 시간(idle time)이라 한다.
- 동기 방식의 첫 번째 상황: 주 스레드가 데이터베이스 처리 결과를 전혀 신경 쓰지 않을 때
  - 데이터 베이스 처리가 완료된 후 주 스레드가 아닌 데이터베이스 스레드가 다음 D, E, F 세 단계를 자체적으로 직접 처리한다.
  - 위의 처리를 위해 콜백함수를 사용한다.

  ```c
  void handle_DEF_after_DB_query() {
    D;
    E;
    F;
  }

  // 주 스레드가 데이터베이스 처리 요청을 보낼 때 이 함수를 매개변수로 전달
  DB_query(request, handle_DEF_after_DB_query);
  ```

  - 데이터베이스 스레드는 데이터베이스 요청을 처리한 후 handle_DEF_after_DB_query 함수를 호출하기만 하면 된다.
    - 이 함수를 데이터베이스 스레드에 정의하고 직접 호출하는 대신 콜백 함수를 통해 전달받아 실행하는 이유: 소프트웨어 조직 구조 관점에서 볼때, 이 작업은 데이터베이스 스레드에서 해야 할 작업이 아니기 때문이다.
  - 주 스레드의 '유휴 시간'이 없어진 대신 그 자리를 끊임없는 작업들이 차지하고 있다. 또 데이터베이스 스레드에도 빈 자리가 거의 없이 작업들이 차지하고 있다.
  - 이런 설계는 시스템 리소스를 더 많이 최대한 활용할 수 있어 요청 처리 속도가 훨씬 더 빨라진다. 사용자 입장에서 볼 때도 시스템 응답 속도가 더 빨라진다.
- 동기 방식의 두 번째 상황: 주 스레드가 데이터베이스 작업 결과에 관심을 가질 때
  - 데이터베이스 스레드는 알림 작동 방식을 이용하여 작업 결과를 주 스레드로 전송해야 한다. 주 스레드는 메시지를 수신하면 이전 사용자 요청의 후반부를 계속 처리한다.
  - 데이터베이스 스레드가 유휴 상태라는 점을 제외하면 주 스레드에는 '유휴 시간'이 없다.
  - 동기 방식의 첫 번째 상황만큼 극단적으로 효율적이지는 않지만, 동기 호출에 비하면 여전히 효율적이다.
- 모든 비동기 호출이 반드시 동기 호출보다 효율적인 것은 아니기 때문에 구체적인 상황에 따라 분석해야 한다.

### Section 2.7 아 맞다! 블로킹과 논블로킹도 있다

- 동기 또는 비동기를 이야기할 때 항상 두 가지 대상을 언급한다.
- 동기는 A와 B라는 두 대상이 강하게 결합된 것을 의미한다. 작업 A가 작업 B에 의존하는 경우이며, 이런 의존 관계가 존재할 때 A와 B는 동기이다.
- A와 B가 강한 결합과 같은 제약이 없어 각자 자신의 작업을 실행할 수 있을 때 A와 B는 비동기이다.

#### 블로킹과 논블로킹

- 블로킹(blocking)과 논블로킹(non-blocking)은 프로그래밍에서 함수를 호출할 때 주로 사용된다.
- 함수 A가 함수 B를 호출할 때, 함수 B를 호출함과 동시에 운영 체제가 함수 A가 실행 중인 스레드나 프로세스를 일시 중지시킨다면 함수 B에 대한 호출 방식은 블로킹 방식이며, 그렇지 않다면 논블로킹 방식이다.
- 블로킹 호출 핵심은 스레드 또는 프로세스가 일시 중지되는 것이다.

#### 블로킹의 핵심 문제: 입출력

- 일반적으로 블로킹은 대부분 입출력과 관련이 있다.
- 프로그램, 스레드 또는 프로세스가 입출력 작업을 할 때는 우리 스레드에서 입출력 과정이 실행되는 동안 CPU 제어권을 다른 스레드에 넘겨 다른 작업을 할 수 있도록 해야 한다. 이후 입출력 작업이 완료되면 다시 CPU 제어권을 우리 스레드 또는 프로세스에서 넘겨받아 계속 다음 작업을 실행할 수 있도록 한다.
- 이때 CPU 제어권을 상실했다가 되찾는 시간 동안 스레드나 프로세스는 블로킹되어 일시중지된다.

#### 논블로킹과 비동기 입출력

- 네트워크 데이터 수신을 예로 들어 논블로킹 호출을 살펴본다.
- 데이터를 수신하는 함수인 recv가 논블로킹이면 이 함수를 호출할 때 운영 체제는 스레드를 일시 중지시키는 대신 recv 함수를 즉시 반환한다.
- 이후 호출 스레드는 자신의 작업을 계속 진행하며, 데이터 수신 작업은 커널이 처리한다.
- 두 가지 작업은 병행 처리된다.
- 데이터를 수신했는지는 어떻게 알 수 있을까? 세 가지 방법이 있다.
  - 논블로킹 방식의 recv 함수 외에 결과를 확인하는 함수를 함께 제공하고, 해당 함수를 호출하여 수신된 데이터가 있는지 확인
  - 데이터가 수신되면 스레드에 메시지나 신호 등을 전송하는 알림 작동 방식 사용
  - recv 함수를 호출할 때, 데이터 수신 처리를 담당하는 함수를 콜백 함수에 담아 매개변수로 전달한다. 이때 recv 함수는 콜백 함수를 지원해야 한다.
- 이것이 바로 논블로킹 호출이며, 이런 유형의 입출력 작업을 비동기 입출력(asynchronous input/output)이라고 부른다.
- 블로킹 호출 방식과 비교해 본다면, 비동기 입출력 방식의 코드 작성이 그다지 직관적이지는 않다.

#### 피자 주문에 비유하기

- 블로킹 호출: 피자 가게에 직접 가서 피자를 주문하는 것
- 논블로킹 호출: 전화로 피자를 주문하는 것
- 논블로킹 상황에서 피자가 완성되었는지 어떻게 알 수 있는가?
  - 인내심이 강한 경우: 배달이 도착하면 알림이 올 것이기 때문에 할 일을 할 수 있다. 주문자와 피자를 굽는 작업은 비동기이다.
  - 인내심이 부족한 경우: 5분마다 전화를 걸어 피자가 완성되었는지 물어본다. 5분 마다 전화는 해야 하지만, 여전히 주문자는 할 일을 할 수 있다. 이때 주문자와 피자를 굽는 작업은 여전히 비동기이다.
  - 인내심이 없는 경우: 5분마다 전화를 걸어 피자가 완성되었는지 물어보고, 5분마다 전화하는 일을 제외하고는 아무것도 하지 않는다. 이제 주문자와 피자를 굽는 작업은 더 이상 비동기가 아니라 동기가 된다.
- 논블로킹이 반드시 비동기를 의미하지 않는다.

#### 동기와 블로킹

- 동기는 블로킹과 다소 유사하다.
- 프로그래밍 관점에서 보면, 동기 호출은 반드시 블로킹이 아닌 반면에 블로킹 호출은 모두 확실한 동기 호출이다.

```c
int sum(int a, int b) {
  return a + b;
}

void funcA() {
  sum(1, 1);
}
```

- sum 함수에 대한 호출은 동기이지만, funcA 함수가 sum 함수를 호출했다고 해서 블로킹되거나 스레드가 일시 중지되지 않는다.

#### 비동기와 논블로킹

- 예: 네트워크 데이터 수신
- 비동기이자 논블로킹 코드 

  ```c
  void handler(void *buf) {
    // 수신된 네트워크 데이터 처리
  }

  while(true) {
    fd = accept();
    // 데이터를 수신하는 recv 함수
    recv(fd, buf, NON_BLOCKING_FLAG, handler);  // 호출 후 바로 반환, 논블로킹 
  }
  ```

  - recv 함수는 논블로킹 호출이므로, 네트워크 데이터를 처리해 주는 handler 함수를 recv 함수에 콜백으로 전달해야 한다. 
- 동기이자 논블로킹 코드
  
  ```c
  void handler(void *buf) {
    // 수신된 네트워크 데이터 처리
  }

  while(true) {
    fd = accept();
    recv(fd, buf, NON_BLOCKING_FLAG);  // 호출 후 바로 반환, 논블로킹

    // check 함수: 네트워크 데이터 도착을 감지하는 전용 함수
    while(!check(fd)) {
      // 순환 감지
    }

    handler(buf);
  }
  ```

  - 여기에서도 recv 함수는 논블로킹으로 호출되지만, while 반복문에서 끊임없이 감지를 시도하여 데이터가 도착하기 전까지는 handler 함수를 사용할 수 없게 된다.
  - 이 코드는 반복문에서 CPU 리소스가 쓸데없이 소모되어 매우 비효율적이므로 이런 코드는 작성해서는 안된다.
- 논블로킹이더라도 전체적으로 반드시 비동기라는 의미는 아니며, 이는 코드 구현 방식에 따라 달라진다.

### Section 2.8 높은 동시성과 고성능을 갖춘 서버 구현

#### 다중 프로세스 

- 가장 먼저 출현한 기술은 가장 간단한 형태의 병행 처리 방식의 일종인 다중 프로세스를 사용하는 것이다.
- 리눅스 세계에서는 fork 방식을 이용하여 여러 자식 프로세스를 생성할 수 있다. 부모 프로세스가 사용자 요청을 먼저 수신하고, 자식 프로세스를 생성해서 해당 사용자의 요청을 처리하도록 한다.
- 이 같은 방식은 모든 요청에 각각 대응하는 프로세스(process-per-connection)가 있다. 장점은 다음과 같다.
  - 프로그래밍이 간단하며 매우 이해하기 쉽다.
  - 개별 프로세스의 주소 공간은 서로 격리되어 있기 때문에 하나의 프로세스에 문제가 발생하여 강제 종료되더라도 다른 프로세스에는 영향을 미치지 않는다.
  - 다중 코어 리소스를 최대한 활용할 수 있다.
- 단점
  - 각 프로세스의 주소 공간이 서로 격리되어 있어, 프로세스 간에 서로 통신이 필요할 때 난이도가 더 올라가며, 프로세스의 통신 작동 방식을 사용해야 한다.
  - 프로세스를 생성할 때 부담이 상대적으로 크고, 프로세스의 빈번한 생성과 종료는 의심의 여지없이 시스템 부담을 증가시킨다.

#### 다중 스레드

- 스레드는 프로세스 주소 공간을 공유하기 때문에 스레드 간 통신을 위해 별도의 통신 작동 방식을 사용할 필요가 없다.
- 스레드는 집을 등에 지고 다니는 소라게와 비슷하다. 집에 해당하는 주소 공간은 프로세스가 소유하고 있으며, 스레드 자신은 집을 빌린 임차인에 불과하다. 따라서 매우 가벼울 뿐만 아니라 생성과 종료에 드는 부담이 적다.
- 각 요청에 대응하는 스레드(thread-per-connection)를 생성할 수 있으며, 설령 파일 읽기와 같은 입출력 작업으로 스레드 중 일부가 블로킹되어 일시 중지되더라도 다른 스레드에 영향을 미치지 않는다.
- 스레드는 프로세스 주소 공간을 공유하기 때문에 스레드 간 '통신'에 있어 편리함을 제공하지만 그와 동시에 수많은 문제를 일으키기도 한다.
- 스레드는 서로 같은 주소 공간을 공유하기 때문에 하나의 스레드에 문제가 발생하여 강제 종료되면 같은 프로세스를 공유하는 모든 스레드와 프로세스가 한꺼번에 강제 종료된다.
- 또한 여러 스레드가 동시에 공유 리소스의 데이터를 읽고 쓸 수 없다는 부작용이 있습니다. 공유 데이터의 주소를 동시에 쓰려고 하면 스레드 안전 문제가 발생하므로 반드시 동기화 시 상호 배제와 같은 작동 방식을 사용해야 한다. 더군다나 교착 상태처럼 일련의 문제를 일으킬 수 있어 다중 스레드가 일으키는 이런 문제를 해결하는 데 프로그래머의 귀중한 시간 중 상당 부분을 할애해야 한다.
- 이렇듯 스레드에도 단점이 있기는 하지만 다중 프로세스와 비교할 때 스레드가 훨씬 더 유리한 고지를 점령하고 있다. 사용자 규모가 크지 않은 경우 다중 스레드로도 충분히 처리 가능하다. 하지만 동시 요청 수가 매우 많을 때는 다중 스레드만으로 감당하기가 어렵다.

#### 이벤트 순환과 이벤트 구동

- 지금까지는 '병행'이라는 단어를 언급할 때 프로세스와 스레드를 떠올렸다.
- 병행 프로그래밍을 위한 또 하나의 기술은 GUI 프로그래밍과 서버 프로그래밍에서 널리 사용되는 이벤트 기반 동시성(event-based concurrency)을 이용한 이벤트 기반 프로그래밍(event-driven programming)이다.
- 이벤트 기반 프로그래밍 기술의 두 가지 요소
  - 이벤트(event): 서버에서 말하는 이벤트는 대부분 입출력에 관계된 것이다. 예를 들어 네트워크 데이터의 수신 여부, 파일의 읽기 및 쓰기 가능 여부 등이 관심 대상인 이벤트에 해당한다.
  - 이벤트를 처리하는 함수: 이 함수를 일반적으로 이벤트 핸들러(event handler)라고 한다.
- 이벤트가 도착하면 이벤트 유형을 확인한 후 해당 유형에 대응하는 이벤트 처리 함수인 이벤트 핸들러를 찾은 후 직접 이벤트 핸들러를 호출하면 된다.
- 기본적으로 이벤트는 계속 발생할 수 있다. 서버에서 이벤트는 바로 사용자 요청이며, 이 이벤트를 계속 수신하고 처리해야 한다. 따라서 while 또는 for 반복문을 사용하여 반복적으로 처리할 필요가 있다. 이 반복을 이벤트 순환(event loop)이라고 한다.

- 의사 코드를 이용하여 이벤트 순환을 표현

```c

while(true) {
  event = getEvent();  // 이벤트 수신 대기
  handler(event);  // 이벤트 처리 
}
```

- 이벤트 순환에서 수행해야 하는 작업은 매우 간단하다. 이벤트가 도착할 때까지 기다렸다가 대응하는 이벤트 핸들러를 호출하면 된다.
- 하지만, 해결해야 할 두 가지 문제가 있다.
  - 이벤트 소스에 관한 문제이다. 앞의 의사 코드에 있는 getEvent 같은 함수 하나로 어떻게 여러 이벤트를 가져올 수 있을까? 서버 프로그래밍 분야의 해결책은 입출력 다중화(input/output multiplexing) 기술
  - 이벤트를 처리하는 handler 함수가 반드시 이벤트 순환과 동일한 스레드에서 실행되어야 할까?

#### 첫 번째 문제: 이벤트 소스와 입출력 다중화

- 리눅스와 유닉스 세계에서는 모든 것이 파일로 취급된다.
- 프로그램은 모두 파일 서술자(file descriptor)를 사용하여 입출력 작업을 실행하며, 소켓(socket)도 예외는 아니다.
- 사용자 연결이 열 개고 이에 대응하는 소켓 서술자가 열 개 있는 서버가 데이터를 수신하려고 대기 중이라고 가정한다. 이를 처리하는 가장 간단한 방법은 다음과 같다.

```c
recv(fd1, buf1);
recv(fd2, buf2);
recv(fd3, buf3);
recv(fd4, buf4);
// ...
```

- 이와 같이 지나치게 단순한 코드는 분명 문제가 있다. 첫 번째 사용자가 데이터를 보내지 않는 한 recv(fd1, buf1) 코드는 반환되지 않으므로 서버가 두 번째 사용자의 데이터를 수신하고 처리할 기회가 사라진다.
- 더 나은 접근 방식은 운영 체제에 다음 내요을 전달하는 작동 방식을 사용하는 것이다. '저 대신 소켓 서술자 열 개를 감시하고 있다가, 데이터가 들어오면 저에게 알려 주세요.' 이런 작동 방식을 입출력 다중화라고 하며, 이와 같은 작동 방식 중 리눅스 세계에서 제일 유명한 것이 바로 epoll이다.

```c
// epoll 생성
epoll_fd = epoll_create();

// 서술자를 epoll이 처리하도록 지정
Epoll_ctl(epoll_fd, fd1, fd2, fd3, fd4, ...);

while(1) {
  int n = epoll_wait(epoll_fd);

  for(i = 0; i < n; i++) {
    // 특정 이벤트 처리
  }
}
```

- epoll은 이벤트 순환을 위해 탄생했다.

#### 두 번째 문제: 이벤트 순환과 다중 스레드

- 이벤트 핸들러에 다음 두 가지 특징이 있다고 가정해보자.
  - 입출력 작업이 전혀 없다.
  - 처리 함수가 간단해서 소요 시간이 매우 짧다.
- 이벤트 핸들러와 이벤트 순환을 동일한 스레드에서 실행할 수 있다.
  - 이 경우 요청은 순차적으로 처리되는데, 모든 요청이 단일 스레드에서 순차적으로 처리된다.
  - 요청을 처리하는 데 시간이 걸리지 않는다는 것을 전제로 하기에 서버는 짧은 시간에도 많은 요청을 처리할 수 있다. 또 요청이 순차적으로 처리되더라도 사용자 입장에서는 응답이 눈에 띄게 지연된다고 느낄 일은 없다.
- 그런데 사용자 요청을 처리하는 데 CPU 시간을 많이 소모한다면 어떻게 해야 할까?
  - 이때도 여전히 단일 스레드를 사용하고 있다면 사용자는 시스템 응답이 너무 느리다고 불평할 것이다.
- 따라서 요청의 처리 속도를 높이고 최신 컴퓨터 시스템의 다중 코어를 최대한 활용하려면 다중 스레드의 도움이 필요하다.
  - 이제 이벤트 핸들러는 더 이상 이벤트 순환과 동일한 스레드에서 실행되지 않고 독립적인 스레드에 배치된다.
  - 작업자 스레드(worker thread) n 개와 이벤트 순환 스레드(event loop thread) 한 개가 생성되는데, 이벤트 순환은 요청을 수신하면 간단한 처리 후 바로 각각의 작업자 스레드에 분배할 수 있다.
- 다중 스레드를 이용한 병행 실행은 시스템의 다중 코어를 최대한 활용하여 요청 처리를 가속화한다. 물론 이 작업자 스레드를 스레드 풀(thread pool)로 구현하는 것도 가능하다.
- 이런 설계 방법을 반응자 패턴(reactor pattern)이라고 한다.

#### 이벤트 순환과 입출력

- 상황을 업그레이드하여 좀 더 복잡하게 바꾸어 보자. 요청 처리 과정에 입출력 작업도 포함된다고 가정해 보자.
- 이때 입출력 작업도 두 가지 상황으로 나누어 이야기해야 한다.
  - 입출력 작업에 대응하는 논블로킹 인터페이스가 있는 경우: 이때는 직접 논블로킹 인터페이스를 호출해도 스레드가 일시 중지되지 않으며, 인터페이스가 즉시 반환되므로 이벤트 순환에서 직접 호출하는 것이 가능하다.
  - 입출력 작업에 블로킹 인터페이스만 있는 경우: 이때는 이벤트 순환 내에서 절대로 어떤 블로킹 인터페이스도 호출하면 안된다. 절대로! 그렇지 않으면 이벤트 순환 스레드가 일시 중지될 수 있으며, 이는 이벤트 순환이라는 엔진이 멈추는 것에 해당하기 때문에 전체 시스템이 모두 앞으로 나아갈 수 없게 된다. 따라서 블로킹 입출력 호출이 포함된 작업은 작업자 스레드에 전달해야 한다. 그래야만 이 작업으로 해당 작업자 스레드가 일시 중지되더라도 다른 작업자 스레드에 문제를 일으키지 않는다.
- 사실 전체적인 프레임워크만 확정되어 있다면 개발자는 handler 함수에 대한 프로그래밍만 하면 된다. 

![](/image/event-loop-input-output.png)

#### 비동기와 콜백 함수 

- 프로젝트 초기에는 handler 함수 기능이 데이터베이스를 처리하여 반환하는 것처럼 매우 간단할 수 있지만, 비지니스가 발전하면서 서버 기능은 점점 더 복잡해졌다.
- 보통 서버 기능은 용도에 따라 여러 부분으로 나뉠 수 있으며, 각 부분은 별도의 서버에 배치된다.
- 예를 들어 사용자가 전자 상거래 앱에서 상품을 검색할 때, 하나의 검색 요청에 네 가지 백엔드(backend) 서비스가 관여한다고 가정해보자.
- 먼저 검색 서버로 요청이 전송되면 간단한 처리를 진행한 후 서버 A에 사용자 프로필과 같은 상세 정보를 요청한다. 다음으로 사용자의 검색어와 서버 A에서 얻은 사용자 프로필을 결합하여 서버 B에 상품 검색을 요청한 후 다시 서버 C에 재고 여부를 조회하여 일치하는 상품 정보를 가져온다. 마지막으로 검색 서비스는 최종 결과에서 재고가 없는 상품을 필터링한 최종 결과를 사용자에게 반환한다.
- 서버는 일반적으로 원격 프로시저 호출(remote procedure call, RPC)을 통해 통신한다.
- RPC는 네트워크 설정, 데이터 전송, 데이터 분석 등 지루한 작업을 담아 프로그래머가 일반 함수를 호출하는 것 처럼 네트워크로 통신할 수 있도록 한다.

```c
GetUserInfo(request, response);
```

- 외부에서 보면 일반적인 함수이지만, 이 함수의 최하위 계층에서는 네트워크 통신을 수행할 수 있다. 대상 서버에 요청을 보내고 그 응답을 받아 매개변수 response에 저장한다.
- 해당 서버에 대응하는 handler 함수는 다음과 같이 작성할 수 있다.

```c
void handler(request) {
  A;
  B;
  GetUserInfo(request, response);  // 서버 A에 요청
  C;
  D;
  GetQueryInfo(request, response);  // 서버 B에 요청
  E;
  F;
  GetStockInfo(request, response);  // 서버 C에 요청
  G;
  H;
}
```

- 이 중에서 Get으로 시작하는 것은 RPC 호출이다. 주의할 점은 이 RPC 호출들은 모두 블로킹 호출이 때문에 사용자가 응답하기 전에는 함수가 반환되지 않는다.
- 위의 handler 함수 구현 방법의 장점은 코드가 명확하고 이해하기 쉽다는 것이다. 반면에 유일한 문제는 불로킹 호출로 스레드가 일시 중지될 수 있고 블로킹 호출이 여러 번 발생하면 스레드가 빈번하게 중단될 수 있다는 것이다.
- 따라서 동기 방식의 RPC 호출을 비동기 호출로 수정해야 한다.
- 비동기 호출은 호출 스레드를 블로킹하지 않기 때문에 함수가 즉시 반환된다. 단, 함수가 반환될 때 사용자 응답에 대한 결과가 없을 수 있다. 이때는 반드시 Get* 함수를 호출한 후 처리할 내용을 콜백 함수에 담아 RPC 호출에 포함한다.

```c
void handler_after_GetStockInfo(response) {
  G;
  H;
}

void handler_after_GetQueryInfo(response) {
  E;
  F;
  GetStockInfo(request, handler_after_GetStockInfo);  // 서버 C에 요청
}

void handler_after_GetUserInfo(response) {
  C;
  D;
  GetQueryInfo(request, handler_after_GetQueryInfo);  // 서버 B에 요청
}

void handler(request) {
  A;
  B;
  GetUserInfo(request, handler_after_GetUserInfo)  // 서버 A에 요청
}
```

- 이제 주 프로세스는 네 개로 분할되고, 콜백 안에 콜백이 포함되었다. 하지만 사용자 서비스가 더 많아지면 이런 형태의 코드는 거의 관리가 불가능하다. 설녕 비동기 프로그래밍이 시스템 리소스를 더 잘활용한다고 해도 말이다.
- 비동기 프로그래밍의 효율성과 동기 프로그래밍의 단순성을 결합한 기술인 코루틴으로 이 문제를 해결할 수 있다.

#### 코루틴: 동기 방식의 비동기 프로그래밍

- handler 함수를 코루틴에서 실행한다.

```c
void handler(request) {
  A;
  B;
  GetUserInfo(request, response);  // 서버 A에 요청
  C;
  D;
  GetQueryInfo(request, response);  // 서버 B에 요청
  E;
  F;
  GetStockInfo(request, response);  // 서버 C에 요청
  G;
  H;
}
```

- handler 함수의 코드 구현은 동기로 작성한다. 하지만 yield로 CPU 제어권을 반환하는 등 RPC 통신이 시작된 후 적극적으로 바로 호출된다는 점은 다르다. 
- 코루틴이 일시 중지되더라도 작업자 스레드가 블로킹되지 않는다. 이것이 코루틴과 스레드를 사용하는 블로킹 호출의 가장 큰 차이점이다.
- 코루틴이 일시 중지되면 작업자 스레드는 준비 완료된 다른 코루틴을 실행하기 위해 전환되며, 일시 중지된 코루틴에 할당된 사용자 서비스가 응답한 후 그 처리 결과를 반환하면 다시 준비 상태가 되어 스케줄링 차례가 돌아오길 기다린다. 이후 코루틴은 마지막으로 중지되었던 곳에서 이어서 계속 실행된다.

![](/image/coroutine-server.png)

- 이벤트 순환은 요청을 받은 후 handler 함수를 코루틴에 담아 스케줄링과 실행을 위해 각 작업자 스레드에 배포
- 작업자 스레드는 코루틴을 획득한 후 진입 함수인 handler를 실행
- 어떤 코루틴이 RPC 요청으로 능동적으로 CPU의 제어권을 반환하면 작업자 스레드는 준비 상태인 다른 코루틴 실행
- 코루틴이 블로킹 방식으로 RPC 호출을 하더라도 작업자 스레드는 블로킹 되지 않기 때문에 시스템 리소스를 효율적으로 사용할 수 있다.

#### CPU, 스레드, 코루틴

- CPU, 스레드, 코루틴은 서로 다른 계층 구조에 위치한다.
  - 하드웨어: CPU
    - 기계 명령어를 실행하여 컴퓨터를 움직이게 한다.
  - 커널 상태: 스레드
    - 커널 상태 스레드라고 하며, 커널로 생성되고 스케줄링 한다.
    - 커널은 스레드 우선순위에 따라 CPU 연산 리소스를 할당한다.
  - 사용자 상태: 코루틴
    - 커널 입장에서 알 수 없는 요소로, 코루틴이 얼마나 많이 생성되었든 커널은 이와 관계없이 스레드에 따라 CPU 시간을 할당한다.
    - 스레드에 할당된 CPU 시간을 사용자 상태에서 재차 할당하는 것이다. 이 할당은 사용자 상태에서 발생하므로 코루틴을 사용자 상태 스레드라고도 한다.

### Section 2.9 컴퓨터 시스템 여행: 데이터, 코드, 콜백, 클로저에서 컨테이너 가상 머신까지

#### 코드, 데이터, 변수, 포인터

- 메모리가 코드로 구성된 명령어 외에 명령어가 작동하는데 필요한 데이터도 저장할 수 있다.
- 메모리에 저장된 데이터는 구조체인 인스턴스일 수도 있고, 객체일 수도 있으며, 배열일 수도 있다. 이러한 데이터를 변수라고 한다.
- 여러 변수를 사용하여 동일한 데이터를 참조할 수 있다.
  - C 언어에서는 포인터(pointer)라고 한다.
  - 포인터 개념을 사용하지 않는 언어에서는 참조(reference)라고 한다.

#### 콜백 함수와 클로저

- 동일한 데이터를 참조하는 변수가 여러 개 있을 수 있듯이, 변수 여러 개가 동일한 코드를 참조할 수 있다.
- 특정 언어에서는 코드를 할당, 사용, 매개변수로 전달, 반환값으로 사용 등 일반 변수를 다루듯이 처리할 수 있을 때 일급 객체 함수(first-class function)라고 한다.
  - C 언어에서는 함수가 일급 객체가 아니기 때문에 함수에서 다른 함수를 반환할 수 없다.
  - 파이썬에서는 함수가 일급 객체이므로 함수를 일반 변수처럼 반환할 수 있다.
- 함수가 다른 함수에 매개변수로 전달될 때 해당 함수를 콜백 함수(callback function)라고 한다.
- 콜백 함수는 실제로 코드 정의는 A에서 하지만 호출은 B에서 하는 것처럼 정의와 호출을 서로 다른 곳에서 한다.
- 하지만 때로는 코드가 A에서 정의될 뿐만 아니라, A에서 생성된 데이터를 사용할 수 있어야 할 때가 있다. 
- 콜백 함수를 일부 데이터와 한데 묶어 변수로 취급할 때 클로저(closure)가 탄생한다.

```python
def add():
  b = 10

  def add_inner(x):
    return b + x
  
  return add_inner

f = add()
print(f(2))
```

- add_inner 함수는 두 가지 데이터를 사용한다. 하나는 add 함수 내에서 정의된 b 변수고, 다른 하나는 사용자가 전달하는 매개변수로 여기서는 2가 그 값에 해당한다.
- f 함수가 호출되어야 add_inner 함수에 필요한 모든 데이터를 얻을 수 있다.
- add_inner 함수는 단순한 코드일 뿐만 아니라 실행 시간 환경인 b 변수를 묶어서 전달하는 클로저이기도 하다.

#### 컨테이너와 가상 머신 기술

- 어떤 함수가 CPU를 능동적으로 일시 중지하고 다음에 함수가 다시 호출될 때 앞에서 중단된 지점에서 계속 실행하는 것이 가능할 때, 이 함수가 바로 코루틴에 해당한다.
- 함수의 일시 중지와 재개가 커널 상태에서 구현되는 경우에는 스레드라고 한다.
- 스레드에 주소 공간처럼 종속된 실행 시 리소스를 결합한 것이 프로세스다.
- 프로그램이 구성, 라이브러리처럼 프로그램이 의존하는 실행 환경과 묶인 것을 컨테이너(container)라고 한다.
- 컨테이너는 일종의 가상화 기술로서 운영 체제를 가상화한다.
- 컨테이너는 운영체제에서 제공하는 기능을 이용하여 프로세스를 격리하고 CPU, 메모리, 디스크에 대한 접근을 제어하는 방식으로 컨테이너에 포함된 프로세스가 전체 운영 체제 안에서 자기 자신의 프로세스만 존재하고 있다고 간주하게 한다.
- 컨테이너를 넘어 좀 더 넓은 범위의 가상화 기술을 사용하면 소프트웨어뿐만 아니라 하드웨어도 가상화할 수 있다.
  - 가상화 기술은 소프트웨어를 이용하여 컴퓨터의 하드웨어를 추상화하고, 하드웨어 리소스를 가상 컴퓨터 여러 개로 나눈다. 그리고 그 위에 운영 체제를 실행하면 이 운영 체제는 하드웨어의 리소스를 가져와 사용할 수 있게 된다.
  - 바로 가상 머신 감시자(virtual machine monitor)가 이런 작업을 하는 소프트웨어로 흔히 이를 하이퍼바이저(hypervisor)라고 한다.
  - 가상 머신 감시자에서 실행되는 운영 체제를 가상 머신이라고 한다.
- 소프트웨어를 사용하면 하나의 추상화 계층 위에 또 다른 추상화 계층을 상대적으로 쉽게 올릴 수 있다.

## Chapter 3. 저수준 계층? 메모리라는 사물함에서부터 시작해보자 

CPU는 메모리 도움 없이는 동작이 불가능하다. 컴퓨터 시스템에서 연산과 저장을 담당하는 것은 각각 CPU와 메모리이다.

### Section 3.1 메모리의 본질, 포인터와 참조 

#### 메모리의 본질은 무엇일까? 사물함, 비트, 바이트, 객체

- 가장 작은 단위를 기준으로 본다면 메모리도 사물함 형태의 구성을 하고 있지만, 메모리에서는 사물함 대신 메모리 셀(memory cell)이라는 표현을 사용한다.
- 메모리 셀에는 0과 1만 보관할 수 있다. 0과 1을 가르켜 1비트(bit)라고 한다.
- 더 많은 정보를 표현하려면 더 많은 비트가 필요하므로 비트 여덟 개를 묶어 정보를 나타내는 하나의 단위인 1바이트(byte)를 사용한다.
- 각 바이트마다 번호를 붙인다. 모든 바이트는 메모리 내 자신의 주소를 가지고 있으며 이 주소를 메모리 주소(memory address)라고 한다.
- 메모리 주소 한 개를 사용하여 특정한 사물함 여러 개를 찾을 수 있으며, 이를 주소 지정(addressing)이라고 한다.
- 하지만 1바이트 역시 8비트이기 때문에 정보를 표현하는 능력에 한계가 있다. 
  - 8비트로 만들 수 있는 조합은 $2^8$인 256개에 불과하므로 이를 부호 없는 정수(unsigned integer)로 표현하면 0부터 255까지 숫자만 표현 가능하다.
- 따라서 일반적으로 4바이트를 묶어 하나의 정수로 표현하는 단위로 사용
  - 4바이트는 32비트로 $2^32$개, 즉 4,294,967,296개의 조합이 가능하기 때문이다.
- 서로 다른 정보 세 개를 표현하려면 12바이트가 필요하다. 12바이트를 사용해서 정보를 조합하여 표시하는 것을 프로그래밍 언어에서 구조체(structure) 또는 객체(object)라고 표현한다.

#### 메모리에서 변수로: 변수의 의미

- 1 + 2 값을 계산하고 싶다고 가정해보자.
- 먼저 숫자 1과 숫자 2를 메모리에 저장해야 한다. CPU는 메모리에서 값을 읽어 레지스터에 저장해야 연산을 수행할 수 있다.
- 먼저 숫자 1을 6번 사물함에 넣는다. 메모리에 정보를 저장할 때 store 명령어를 사용한다.
  - `store 1 6`
- 읽기는 load 명령어를 사용한다.
  - `load r1 6`
  - 6번 사물함에 저장된 숫자를 r1 레지스터에 읽어 오기 
- 숫자들이 값과 메모리 주소를 모두 나타낼 수 있기 때문에 해석이 모호해진다. $ 기호가 있으면 값이고, 없다면 메모리 주소를 의미한다.
  - `store $1 6`
  - `load r1 6`
- 하지만 '주소 6'이라는 표현은 인간에게 익숙하지 않다. 부르기 쉬운 별칭을 붙여보자.
  - '주소 6'에 a라는 이름을 붙인다.
  - a에 저장된 값이 바로 1이다.
  - `a = 1`
- 이렇게 변수라는 단어가 탄생했다.
  - 변수 a의 뒤에는 다음과 같은 두 의미가 있다.
    - 값 1을 나타낸다.
    - 이 값은 메모리 주소 6에 저장된다.
- 다음과 같은 표현을 추가해보자.
  - `b = a`
  - b 변수를 위해 2번 사물함에 b 변수를 저장한다.
  - a 변수의 숫자 데이터를 완전히 복제했다.
- a 변수가 1 바이트의 데이터뿐만 아니라 구조체나 객체처럼 여러 바이트를 차지한다고 가정한다.
  - 이제 a 변수는 5바이트를 차지하며, 이제는 전체 메모리의 절반 이상에 해당한다.
  - 이런 상황에서 b = a를 표현해야 한다면, 메모리 공간이 부족하다.
  - 전체 메모리 크기가 8바이트에 불과한데, 복사 방법을 사용하면 두 변수가 나타내는 데이터만으로도 이미 10바이트를 차지하기 때문이다.

#### 변수에서 포인터로: 포인터 이해하기

- 메모리 주소만 알고 있으면 해당 데이터를 찾을 수 있다.
- 메모리 주소 역시 하나의 숫자로 이 역시 해당 데이터가 차지하고 있는 메모리 공간 크기와는 무관하다.
- 만약 b 변수도 a 변수를 가리키고 있다면 굳이 불필요한 데이터의 복사본을 만들 필요가 없다. 그 주소를 저장하면 된다.
  - a 변수는 메모리 주소 3에 위치하고 있으므로 b 변수에는 숫자 3을 저장할 수 있다.
  - b 변수가 저장하고 있는 숫자는 더 이상 값으로 해석되지 않고 메모리 주소로 해석된다.
- 변수가 값뿐만 아니라 메모리 주소까지 저장할 수 있게 되면서 포인터가 탄생했다.
- 포인터를 주소 자체라고 언급할 때가 많이 있는데, 사실 이는 어셈블리어 수준에서만 적용되는 이야기이다.
  - 어셈블리어에서 b 변수가 가르키는 값을 적재하려면
  - `load r1 1`: 메모리 주소 1에 있는 숫자 3을 r1 레지스터에 적재한다.
  - 하지만 메모리 주소 1에 있는 값은 메모리 주소로 해석되야 하므로 식별자를 추가한다.
  - `load r1 @1`: 메모리 주소 1에 저장된 값인 3을 읽어 이 값을 메모리 주소로 간주하여 해석한 후 메모리 주소 3이 가리키는 데이터 값을 진짜 데이터로 간주한다.
  - 이를 간접 주소 지정(indirect addressing)이라고 하며, 어셈블리어에는 변수라는 개념이 없기 때문에 어셈블리어를 사용한다면 반드시 이 간접 주소 지정 계층을 알고 있어야 한다.
- 고급 언어에서 포인터는 하나의 변수에 불과하다. 단지 이 변수가 저장하기에 적합한 것이 메모리 주소일 뿐이다. 포인터는 메모리 주소를 더 높은 수준으로 추상화한 것이다.
- 포인터를 더 높은 수준의 추상화라고 하며, 이 추상화 목적은 간접 주소 지정을 감싸기 위한 것이다.
  - 어셈블리어 수준: 주소 1 --> 주소 3 --> 데이터
  - 고급 언어 수준: b --> 데이터

#### 포인터의 힘과 파괴력: 능력과 책임

- 자바와 파이썬 같은 언어에는 포인터가 존재하지 않는다. 이런 프로그래밍 언어에서는 메모리 주소를 직접 노출하지 않아 메모리 주소를 확인할 수 없기에 특정 메모리 위치에 있는 데이터를 조작하는 것이 불가능하다.
- 반면에 C 언어는 메모리 주소를 추상화하지 않으며 훨씬 더 유연하므로 메모리 주소를 프로그래머가 직접 알 수 있다.
- 포인터 개념이 있으면 프로그래머는 메모리 같은 하드웨어를 직접 조작할 수 있지만, 포인터 개념이 없는 프로그래밍 언어에서는 이런 작업이 불가능하다. 이것이 C 언어가 저수준 계층을 제어하는 강력한 힘을 가진 이유이자 C 언어가 시스템 프로그래밍에 가장 먼저 선택되는 중요 원인이기도 하다.
- 직접 메모리를 읽고 쓰는 기능이 모든 상황에 다 필요한 것은 아니며, 이는 자바와 파이썬 같은 언어로 증명됐다. 비록 이 언어에 포인터는 없지만, 포인터 대신 사용할 수 있도록 포인터를 한 번 더 추상화한 참조가 있기 때문이다.

#### 포인터에서 참조(reference)로: 메모리 주소 감추기

- 포인터를 지원하는 대신 참조라는 개념을 제공하는 프로그래밍 언어에서 참조를 사용할 때는 변수의 구체적인 메모리 주소를 얻을 수 없으며, 참조는 포인터와 유사한 구조의 산술 연산을 할 수 없다.
- 참조를 사용하면 데이터를 복사할 필요가 없기 때문에 포인터를 사용할 때와 동일한 효과를 얻을 수 있다.
- 요약하면, 포인터는 메모리 주소를 추상화한 것이고 참조는 포인터를 한 번 더 추상화한 것이라 할 수 있다.

### Section 3.2 프로세스는 메모리 안에서 어떤 모습을 하고 있을까?

- 64비트 시스템에서 메모리 내 프로세스 구조
  - 커널
  - 2^48 - 1
  - 스택 영역(함수 실행 시 정보 저장)
  - 스택 상단
  - 유휴 영역
  - 힙 영역(동적 메모리 할당)
  - 데이터 영역
  - 코드 영역
  - 0x4000000
- 모든 프로세스 주소 공간에는 코드 영역, 데이터 영역, 힙 영역, 스택 영역이 있다.
- 코드 영역(code segment)과 데이터 영역(data segment)은 실행 파일을 초기화할 때 생성되는 영역이다.
- 힙 영역(heap segment)은 동적 메모리 할당에 사용되는데, 구체적으로 C/C++ 언어의 malloc 함수에서 요청한 메모리가 이 영역에 할당된다.
- 스택 영역(stack segment)은 함수 호출에 사용되는 매개변수, 반환 주소, 레지스터 정보 등을 포함한 함수 실행 시 정보를 저장하는데 사용

#### 가상 메모리: 눈에 보이는 것이 항상 실제와 같지는 않다

- 가상 메모리에서 사용되는 주소는 가상 메모리 주소 또는 가상 주소에 해당한다.
- 위의 '메모리 내 프로세스 구조'는 사실 가상적인 구조에 불과하다. 실제 메모리에는 애초에 이런 형태의 구조가 존재할 수 없다.
- 프로세스는 동일한 크기의 '조각(chunk)'으로 나뉘어 물리 메모리에 저장된다.
- 모든 조각은 물리 메모리 전체에 무작위로 흩어져 있다.

#### 페이지와 페이지 테이블: 가상에서 현실로

- 가상 메모리 주소 공간은 물리 메모리에 사상(mapping)되어 있다.
- 가상 메모리 주소와 물리 메모리 주소의 사상 관계가 유지되는 한 프로세스 주소 공간의 데이터가 실제 물리 메모리의 어디에 저장되는지 전혀 신경 쓸 필요가 없다.
- 이런 사상 관계를 유지하는 것을 페이지 테이블이라고 하며, 각각의 프로세스에는 단 하나의 페이지 테이블만 있어야 한다.
- 모든 가상 주소를 물리 주소에 사상하는 대신 프로세스의 주소 공간을 동일한 크기의 '조각'으로 나누고, 이 '조각'을 페이지(page)라고 부른다.

### Section 3.3 스택 영역: 함수 호츨은 어떻게 구현될까?

#### 함수 호출 활동 추적하기: 스택 

- 함수 호출 활동을 추적하면 후입선출(last in first out) 순서로, 본질적으로 스택과 같은 데이터 구조가 처리하기에 적합하다.
- 사실상 이진 트리(binary tree)의 탐색(search)과 같다. 이런 트리 구조의 순회가 재귀 구현뿐만 아니라 스택 구현에도 사용될 수 있는 이유다.

#### 스택 프레임 및 스택 영역: 거시적 관점

- 모든 함수는 실행 시에 자신만의 '작은 상자'가 필요하다. 이 상자 안에는 해당 함수가 실행될 때 사용되는 여러 가지 정보가 저장되어 있으며, 이 상자들은 스택 구조를 통해 구성된다. 
- 여기서 각각의 작은 상자를 스택 프레임(stack frame) 또는 호출 스택(call stack)이라고 한다. 이 구조는 우리가 일반적으로 말하는 프로세스의 스택 영역에 생성된다.
- 이때 프로세스 스택 영역의 높은 주소(highest address)가 맨 위에 있고 낮은 주소 방향으로 커진다.

#### 함수 점프와 반환은 어떻게 구현될까?

- 함수 A가 함수 B를 호출하면, 제어권이 함수 A에서 함수 B로 옮겨진다.
- CPU가 함수 A의 명령어를 실행하다가 함수 B의 명령어로 점프하는 것을 제어권이 함수 A에서 함수 B로 이전되었다고 한다.
- 제어권이 이전될 때는 다음 두 가지 정보가 필요하다.
  - 반환(return): 어디에서 왔는지에 대한 정보
  - 점프(jump): 어디로 가는지에 대한 정보
- 함수 A의 스택 프레임에 call 명령어 다음에 위치한 주소를 넣는다.
  - 함수 A의 스택 프레임 영역이 차지하는 메모리 크기도 증가된다.
- 함수 B가 호출되면 함수 B의 스택 프레임이 생긴다.

#### 매개변수 전달과 반환값은 어떻게 구현될까?

- x86-64에서는 대부분의 경우 매개변수의 전달과 반환값을 가져오는 작업을 레지스터로 한다.
- CPU 내부의 레지스터 수는 제한되어 있다. 만약 전달된 매개변수 수가 사용 가능한 레지스터 수보다 많다면 어떻게 될까? 
- 원래 매개변수 수가 레지스터 수보다 많으면 나머지 매개변수는 스택 프레임에 직접 넣을 수 있기 때문에 새로 호출된 함수(함수 B)가 이전의 함수(함수 A)의 스택 프레임에서 매개변수를 가져오면 된다. 
- 스택 프레임 내용이 더 많아졌다.

#### 지역 변수는 어디에 있을까?

- 매개변수와 마찬가지로 레지스터에 저장할 수 있지만, 로컬 변수 수가 레지스터 수보다 많으면 이 변수들도 스택 프레임에 저장되어야 한다. 스택 프레임 내용이 더 늘었다.

#### 레지스터 저장과 복원

- 레지스터에 지역 변수를 저장하기 전에 반드시 먼저 레지스터에 원래 저장되었던 초기값을 꺼냈다 레지스터를 사용하고 나면 다시 그 초기값을 저장해야한다.
- 이것 역시 함수의 스택 프레임에 저장된다.
- 함수 실행이 완료된 후에는 스택 프레임에 저장되어 있는 초기값을 상응하는 레지스터에 내용으로 복원하기만 하면 된다.

#### 큰 그림을 그려 보자, 우리는 지금 어디에 있을까?

- 앞서 설명했던 스택 프레임은 우리가 흔히 스택 영역이라고 하는 곳에 위치한다.
- 스택 영역은 프로세스 주소 공간의 일부이며, 스택 영역을 확대하면 다음과 같다.
  - 함수 A의 스택 프레임
    - 레지스터 초기값
    - 지역 변수
    - 매개변수 1
    - ...
    - 매개변수 n
    - 반환 주소
  - 함수 B의 스택 프레임
    - ...
- 재귀 함수를 반복해서 호출 하면, 함수가 매번 호출될 때마다 상응하는 스택 프레임은 함수 실행 시 정보를 저장하기 위해 생성되며, 함수 호출 단계가 증가함에 따라 스택 영역이 점점 더 많은 메모리를 차지하게 된다. 
- 하지만 스택 영역의 크기에는 제한이 있으며, 이 제한을 초과하면 바로 그 유명한 스택 넘침(stack overflow) 오류가 발생한다.
- 따라서 프로그래머는 다음 것들을 주의해야 한다.
  - 너무 큰 지역 변수를 만들면 안 된다.
  - 함수 호출 단계가 너무 많으면 안된다.
- 스택 영역의 아래는 유휴 영역(free segment)이다. 스택 영역이 계속 증가하면 유휴 영역을 점유하기 시작하는데, 이 영역에도 역할이 존재한다. 프로그램이 동적 라이브러리에 의존하는 경우에는 프로그램이 사용하는 동적 라이브러리가 이 영역에 적재된다.

### Section 3.4 힙 영역: 메모리의 동적 할당은 어떻게 구현될까?

- 스택 프레임은 스택 영역 내에 구성되기 때문에 함수의 호출 단계가 증가할 때마다 스택 영역이 차지하는 메모리가 늘어난다. 반면에 함수 호출이 완료되면 기존 스택 프레임 정보는 더 이상 사용되지 않으므로 스택 영역이 차지하는 메모리는 그만큼 줄어든다.
- 프로그래머는 앞의 내용을 기반으로 두 가지 내용에 주의해야 한다.
  - 함수 A가 함수 B를 호출할 때, 함수 B에 대한 호출 과정이 완료되면 스택 프레임에 저장되어 있던 내용은 더 이상 사용되지 않고 무효화(invalidation)된다.

    ```c
    int* B() {
      int a = 10;
      return &a;
    }
    ```

    - 함수 B가 스택 프레임에 저장되어 있던 지역 변수 데이터에 대한 포인터를 반환하는 것처럼 이미 사용이 끝난 스택 프레임 정보를 사용해서는 안 된다.
  - 지역 변수 생명주기(lifecycle)는 함수 호출과 동일하다. 이것의 장점은 프로그래머가 지역 변수가 차지하는 메모리의 할당과 반환 문제에 신경 쓸 필요가 없으며 함수를 호출할 때 지역 변수가 바로 스택 프레임에 저장된다는 것이다. 반면에 지역 변수의 단점은 함수를 뛰어넘어 사용하는 것이 불가능하다는 것이다.

#### 힙 영역이 필요한 이유

- 특정 데이터를 여러 함수에 걸쳐 사용해야 한다면 어떻게 해야 할까? 
  - 전역 변수는 모든 모듈에 노출되어 있으며, 때로는 데이터를 모든 모듈에 노출하고 싶지 않을 때도 있을 것이다.
- 이런 종류의 데이터는 프로그래머가 직접 관리하는 특정 메모리 영역에 저장해야 한다.
- 이와 같은 이유로 메모리 수명 주기에는 프로그래머가 완전히 직접 제어할 수 있는 매우 큰 메모리 영역이 필요하며, 이 영역을 바로 힙 영역(heap segment)이라고 한다.
- C/C++ 언어에서는 malloc 함수 또는 new 예약어를 사용하여 힙 영역에 메모리를 요청하며, free 함수나 delete 예약어를 이용하여 해당 메모리를 반환한다.

#### malloc 메모리 할당자 직접 구현하기

- 메모리 할당자 입장에서는 적절한 크기의 메모리 영역을 제공하기만 하면 되고, 할당자는 그 메모리 영역에 무엇을 저장할지까지는 신경 쓰지 않는다. 정수, 연결 리스트, 이진 트리 등 어떤 구조의 데이터도 모두 저장할 수 있으며, 메모리 할당자가 보기에 이런 데이터는 단순한 바이트의 연속에 지나지 않다.
- 힙 영역 위에서 두 가지 문제를 해결해야 한다.
  - malloc 함수를 구현: 누군가 메모리 영역을 요청하면 힙 영역에서 가능한 메모리 영역을 찾아 요청자에게 반환하는 과정을 구현
  - free 함수를 구현: 메모리 영역의 사용이 완료되었을 때 힙 영역에 이 메모리 영역을 반환하는 방법을 구현하는 것

#### 주차장에서 메모리 관리까지



